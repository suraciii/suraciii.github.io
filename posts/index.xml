<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on The Dice Maker</title><link>http://suraciii.github.io/posts/</link><description>Recent content in Posts on The Dice Maker</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Thu, 27 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="http://suraciii.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>.NET Activity API中的一个小陷阱</title><link>http://suraciii.github.io/posts/dotnet-activity-pitfall/</link><pubDate>Thu, 27 Jan 2022 00:00:00 +0000</pubDate><guid>http://suraciii.github.io/posts/dotnet-activity-pitfall/</guid><description>&lt;p>最近在为Orleans改进其分布式追踪组件(&lt;a href="https://github.com/dotnet/orleans/pull/7443">Use DistributedContextPropagator to propagate Activities&lt;/a>)的时候，从AspNetCore中抄了一些代码:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="color:#75715e">// https://github.com/dotnet/aspnetcore/blob/9da42b9fab4c61fe46627ac0c6877905ec845d5a/src/Hosting/Hosting/src/Internal/HostingApplicationDiagnostics.cs#L272
&lt;/span>&lt;span style="color:#75715e">&lt;/span>
&lt;span style="color:#66d9ef">private&lt;/span> Activity? StartActivity(HttpContext httpContext, &lt;span style="color:#66d9ef">bool&lt;/span> loggingEnabled, &lt;span style="color:#66d9ef">bool&lt;/span> diagnosticListenerActivityCreationEnabled, &lt;span style="color:#66d9ef">out&lt;/span> &lt;span style="color:#66d9ef">bool&lt;/span> hasDiagnosticListener)
{
&lt;span style="color:#66d9ef">var&lt;/span> activity = &lt;span style="color:#ae81ff">_&lt;/span>activitySource.CreateActivity(ActivityName, ActivityKind.Server);
&lt;span style="color:#75715e">// ...
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> headers = httpContext.Request.Headers;
&lt;span style="color:#ae81ff">_&lt;/span>propagator.ExtractTraceIdAndState(headers,
&lt;span style="color:#66d9ef">static&lt;/span> (&lt;span style="color:#66d9ef">object?&lt;/span> carrier, &lt;span style="color:#66d9ef">string&lt;/span> fieldName, &lt;span style="color:#66d9ef">out&lt;/span> &lt;span style="color:#66d9ef">string?&lt;/span> fieldValue, &lt;span style="color:#66d9ef">out&lt;/span> IEnumerable&amp;lt;&lt;span style="color:#66d9ef">string&lt;/span>&amp;gt;? fieldValues) =&amp;gt;
{
fieldValues = &lt;span style="color:#66d9ef">default&lt;/span>;
&lt;span style="color:#66d9ef">var&lt;/span> headers = (IHeaderDictionary)carrier!;
fieldValue = headers[fieldName];
},
&lt;span style="color:#66d9ef">out&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> requestId,
&lt;span style="color:#66d9ef">out&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> traceState);
&lt;span style="color:#75715e">// ...
&lt;/span>&lt;span style="color:#75715e">&lt;/span> activity.SetParentId(requestId);
&lt;span style="color:#66d9ef">if&lt;/span> (!&lt;span style="color:#66d9ef">string&lt;/span>.IsNullOrEmpty(traceState))
{
activity.TraceStateString = traceState;
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这段代码的作用是，创建Activity后，从请求头中尝试获取追踪信息（traceid等），如果存在的话，就通过&lt;code>activity.SetParentId(requestId)&lt;/code>将这个新创建的Activity与请求头中的追踪上下文关联，即进入链路成为其中的一个子片段。&lt;/p>
&lt;p>这个逻辑看起来没什么问题，也有相关的单元测试覆盖，于是我把这段代码抄到了Orleans里并最终合并进主干，但是不久后有一个开发者提了issue，报告了其中的问题——&lt;/p>
&lt;blockquote>
&lt;p>在使用OpenTelemetry SDK捕获Activities从而产生分布式追踪信息后，这些Activity所代表的Span并没有根据请求链路关联起来，而是各自成为了独立的链路。&lt;/p>
&lt;/blockquote>
&lt;p>这就十分令人好奇了——这是从AspNetCore代码库里抄来的代码，也有相关测试覆盖，为什么还会有问题？
于是使用OpenTelemetry SDK重现了这个bug并仔细调试后，发现了问题出现的原因：&lt;/p>
&lt;p>OpenTelemetry SDK记录应用的Activity时，有一个默认的采样器(Sampler)，在这个采样器中它会在创建Activity时访问相关&lt;code>ActivityCreationOptions&lt;/code>中的&lt;code>.TraceId&lt;/code>属性，再看其源码：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="color:#75715e">// https://github.com/dotnet/runtime/blob/970d347a1b06951692cfecc1cc12a500158708b1/src/libraries/System.Diagnostics.DiagnosticSource/src/System/Diagnostics/ActivityCreationOptions.cs#L128
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">public&lt;/span> ActivityTraceId TraceId
{
&lt;span style="color:#66d9ef">get&lt;/span>
{
&lt;span style="color:#66d9ef">if&lt;/span> (Parent &lt;span style="color:#66d9ef">is&lt;/span> ActivityContext &amp;amp;&amp;amp; IdFormat == ActivityIdFormat.W3C &amp;amp;&amp;amp; &lt;span style="color:#ae81ff">_&lt;/span>context == &lt;span style="color:#66d9ef">default&lt;/span>)
{
Func&amp;lt;ActivityTraceId&amp;gt;? traceIdGenerator = Activity.TraceIdGenerator;
ActivityTraceId id = traceIdGenerator == &lt;span style="color:#66d9ef">null&lt;/span> ? ActivityTraceId.CreateRandom() : traceIdGenerator();
Unsafe.AsRef(&lt;span style="color:#66d9ef">in&lt;/span> &lt;span style="color:#ae81ff">_&lt;/span>context) = &lt;span style="color:#66d9ef">new&lt;/span> ActivityContext(id, &lt;span style="color:#66d9ef">default&lt;/span>, ActivityTraceFlags.None);
}
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#ae81ff">_&lt;/span>context.TraceId;
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>也就是说，访问&lt;code>.TraceId&lt;/code>时，如果它还没有traceid，就生成一个并返回，最终被配置到新创建的Activity中，而Activity的TraceId只能被配置一次，也就是说如果traceid已经存在，后面的&lt;code>activity.SetParentId(requestId)&lt;/code>就不会产生作用。&lt;/p>
&lt;p>所以最终，每个Activity都单独生成了自己的traceid，没有使用进入父级链路。&lt;/p>
&lt;p>查看&lt;code>SetParentId&lt;/code>这个API的文档时，也发现了建议谨慎使用的注释：&lt;/p>
&lt;blockquote>
&lt;p>This is intended to be used only at &amp;lsquo;boundary&amp;rsquo; scenarios where an activity from another process logically started this activity.&lt;/p>
&lt;/blockquote>
&lt;h4 id="为什么单元测试里没有问题">为什么单元测试里没有问题？&lt;/h4>
&lt;p>单元测试里虽然也使用了采样器，但是并没有在采样器中访问&lt;code>TraceId&lt;/code>，所以不会出现上述问题，而在采样器中加入了对&lt;code>TraceId&lt;/code>的访问后，也成功复现了这个bug&lt;/p>
&lt;h4 id="为什么opentelemetry-sdk采集aspnetcore的activities就没有这个问题">为什么OpenTelemetry SDK采集AspNetCore的Activities就没有这个问题？&lt;/h4>
&lt;p>因为OpenTelemetry SDK没有直接采集AspNetCore生成的Activities，而是hook了相关生命周期事件，生成并采集自定义的Activities，如果它直接采集AspNetCore产生的Activities，也会有这个问题，这是AspNetCore代码中的一个缺陷，有一个&lt;a href="https://github.com/dotnet/aspnetcore/issues/37471#issuecomment-972083624">issue&lt;/a>记录了它&lt;/p>
&lt;p>总结和教训：&lt;/p>
&lt;ul>
&lt;li>只有单元测试是不够的，还要进行端到端的测试&lt;/li>
&lt;li>不能盲目信任“权威”代码，它也有bug&lt;/li>
&lt;li>这种明明只是访问一个属性却产生了副作用的做法是不好的，一方面它容易引入错误，另一方面出错后也很难进行相关的debug&lt;/li>
&lt;/ul></description></item><item><title>设计案例：多优先级规则的分布式任务调度</title><link>http://suraciii.github.io/posts/design-job-scheduler/</link><pubDate>Sat, 22 Jan 2022 00:00:00 +0000</pubDate><guid>http://suraciii.github.io/posts/design-job-scheduler/</guid><description>&lt;h2 id="项目背景">项目背景&lt;/h2>
&lt;p>&lt;em>&lt;strong>这个项目我并未全程参与，只是在方案设计遇到问题时参与了讨论，所以文中对于业务场景和需求的描述并不全面，只记录了讨论中获取到的信息&lt;/strong>&lt;/em>&lt;/p>
&lt;p>一个分布式的数据采集应用，其基本功能为采集各个电商平台上的商品信息，具体要求如下：&lt;/p>
&lt;ul>
&lt;li>应用有多个用户，用户可以上传采集任务&lt;/li>
&lt;li>应用能够并行执行多个任务，可以水平伸缩&lt;/li>
&lt;li>采集任务的执行模块和管理模块&lt;strong>分别独立地部署在独立的两个网络环境中&lt;/strong>&lt;/li>
&lt;/ul>
&lt;h2 id="初始方案">初始方案&lt;/h2>
&lt;p>在此之上，开发者设计出一个初步的方案：&lt;/p>
&lt;p>由一个任务调度中心（manager）负责接收和管理所有由用户上传的任务，并根据相应的设定，分配各个任务给各个采集器（worker）执行，如图所示：&lt;/p>
&lt;p>&lt;img src="http://suraciii.github.io/design-job-scheduler/1.png" alt="">&lt;/p>
&lt;p>这样的模式中，有两个特点&lt;/p>
&lt;ul>
&lt;li>应用被分离成manager和worker，manager负责接收和管理任务，worker负责任务的执行&lt;/li>
&lt;li>master中维护了一个任务队列，如果所有worker都在忙碌状态中时，任务可以在队列中进行排队，并以先进先出的方式等待执行&lt;/li>
&lt;/ul>
&lt;h2 id="出现的问题和新的需求">出现的问题和新的需求&lt;/h2>
&lt;p>这个方案有一些问题：&lt;/p>
&lt;ul>
&lt;li>manager作为任务的控制和调度中心，需要知道每个worker的位置，manager需要监控所有worker的地址、状态等，这样才能有效地将任务分配到一个已启动且空闲的节点&lt;/li>
&lt;li>由于worker和manager处于分离的网络空间，manager获得各个worker的地址会非常麻烦，可能需要配置和维护一个worker列表&lt;/li>
&lt;li>由于worker所处的网络环境的特殊性，甚至需要运维部门协助配置端口转发&lt;/li>
&lt;/ul>
&lt;p>而在开发过程中，也出现了新的需求：&lt;/p>
&lt;ul>
&lt;li>worker有不同的分组，专属任务只能被特定分组的worker执行&lt;/li>
&lt;li>特定分组的worker优先执行专属任务，如果没有专属任务，则执行未被分类的普通任务&lt;/li>
&lt;li>用户上传任务时，可以指定某任务优先执行&lt;/li>
&lt;/ul>
&lt;p>这样的需求下，任务的调度决策开始变得复杂，事情开始变得混乱起来&lt;/p>
&lt;p>对于熟悉一些基本数据结构的开发者来说，如果没有全面详细地了解其需求的话，在这里可能容易想到优先队列，在任务入队时指定任务的优先级，优先队列则会按照相应的优先级将任务出队。
但是了解其具体需求后，则会发现优先队列无法解决上面的专属任务问题，甚至对于“上传优先执行任务”这个需求，其真实的数据结构甚至不是一个先进先出的队列，而是后进先出的栈。&lt;/p>
&lt;h2 id="来自线程调度的启发">来自线程调度的启发&lt;/h2>
&lt;p>这个问题和线程池调度有些类似，在许多编程语言的线程池调度中，也有着类似的&amp;quot;worker&amp;quot;，即线程。这里以我最熟悉的.NET线程池调度为例（Java和Rust中也有类似的机制）：&lt;/p>
&lt;p>在.NET线程池中，每个工作线程都有着自己专属的任务队列(local queue)，也有一个全局队列(global queue)，任务在创建时根据需要被放进相应的队列中。工作线程则按照以下规则来获取和执行任务：&lt;/p>
&lt;ol>
&lt;li>首先尝试从本地队列头部获取任务&lt;/li>
&lt;li>如果本地队列为空，则尝试从全局队列头部获取任务&lt;/li>
&lt;li>如果全局队列也为空，则尝试从其它工作线程的本地队列的尾部获取任务&lt;/li>
&lt;li>如果其它工作线程的本地队列也为空，则进入休眠&lt;/li>
&lt;/ol>
&lt;p>这个机制被叫做work-stealing，能够帮助线程池更有效率、更均衡的进行多线程任务调度。它与前面提到的问题有些不同，比如在采集任务调度中，不需要也不可以“偷取”其它worker的任务&lt;/p>
&lt;p>但是总体上，它给了我一些启发：&lt;/p>
&lt;h3 id="1-这里存在着两种优先级一种是队列中的优先级如先进先出另一个是不同队列之间的优先级本地队列--全局队列--其它线程的本地队列">1. 这里存在着两种优先级，一种是队列中的优先级（如先进先出），另一个是不同队列之间的优先级（本地队列 &amp;gt; 全局队列 &amp;gt; 其它线程的本地队列）&lt;/h3>
&lt;p>结合对需求的梳理，可以得出在这个采集任务的调度中这里面大体上存在3个任务通道，分别是：&lt;/p>
&lt;ul>
&lt;li>先进先出的普通任务通道&lt;/li>
&lt;li>先进先出的专属任务通道&lt;/li>
&lt;li>后进先出的优先任务通道&lt;/li>
&lt;/ul>
&lt;h3 id="2-对不同队列优先级决策属于各个工作线程是工作线程在决定自己应该优先从哪个队列中获取任务">2. 对不同队列优先级决策属于各个工作线程，是工作线程在决定自己应该优先从哪个队列中获取任务&lt;/h3>
&lt;p>这里可以看出，将选择任务通道的决策点转移给worker，并结合“竞争消费”的机制后，任务的调度被简化了许多，每个worker只需要按照既定的规则，从各个任务通道中“抢”任务。&lt;/p>
&lt;p>进一步还发现，由于选择任务通道的决策点被转移到了worker中，这使得manager和worker之间的交互方式，由之前的 manager选择任务然后分配给worker，得以变化为 worker选择通道然后从manager中获取任务
这种交互方式下，manager不再需要知道所有节点的物理位置及状况，只需要worker知道manager的位置就可以了&lt;/p>
&lt;p>基于这些启发，给出了新的解决方案：&lt;/p>
&lt;ul>
&lt;li>用户上传的任务，会根据其分类，分别进入普通通道、专属通道或优先通道&lt;/li>
&lt;li>worker以竞争的方式，从manager中获取任务，任务一旦被某worker获取后，不能再被其它worker获取&lt;/li>
&lt;li>worker首先访问优先通道，再访问自己对应分组的专属通道，最后访问全局通道&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="http://suraciii.github.io/design-job-scheduler/2.png" alt="">&lt;/p>
&lt;p>在和开发者对此方案进行讨论后，确认了其可以较好地满足需求&lt;/p>
&lt;h2 id="总结">总结&lt;/h2>
&lt;p>在这个设计方案中，我其实并没有创新出任何一丁点的东西，所有的思路和答案都来自于已存在的案例和设计模式：&lt;br>
除了上面介绍的.NET线程池调度，对于任务调度这个领域，还有很多值得参考的案例，比如一些CI/CD任务的调度，如Azure DevOps、GitLab和GitHub的CI/CD agent，都能提供非常有价值的参考和启发，又比如在Hangfire项目中，其也有着类似的“多通道”任务调度的设计，任务队列的具体实现就可以参考它。
另外这个设计里还使用了一些其它设计模式，比如一开始的manager/worker模式，比如worker获取任务时使用的竞争消费者模式等。&lt;/p>
&lt;p>而这些模式基本也都是从一些项目中学习来的，比如manager/worker是从Azure DevOps Agent中学到的，竞争消费者是从kafka的消费行为中学到的。&lt;/p>
&lt;p>所以平常对于一些产品和工具，除了学习如何使用它们，学习它们的设计和实现原理也十分有价值，在遇到类似的问题时也许就可以用得上。&lt;/p>
&lt;p>&lt;em>&lt;strong>参考：&lt;/strong>&lt;/em>&lt;/p>
&lt;ol>
&lt;li>&lt;a href="https://en.wikipedia.org/wiki/Work_stealing">Work stealing (Wikipedia)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.microsoft.com/en-us/dotnet/api/system.threading.tasks.taskscheduler?view=net-6.0#the-default-task-scheduler-and-the-thread-pool">.NET TaskScheduler&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://levelup.gitconnected.com/manager-worker-communication-patterns-c3580b9db5db">Manager-Worker Communication Patterns&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/HangfireIO/Hangfire">Hangfire&lt;/a>&lt;/li>
&lt;/ol></description></item><item><title>更有效率地生产更好的应用</title><link>http://suraciii.github.io/posts/build-better-apps/</link><pubDate>Thu, 20 Jan 2022 00:00:00 +0000</pubDate><guid>http://suraciii.github.io/posts/build-better-apps/</guid><description>&lt;p>想象一个产品，比如一辆汽车，它是如何出现，又是如何成为我们在街上见到的那样，而它又结束在何处呢？&lt;/p>
&lt;p>首先，任何产品都不是凭空出现的，它们都是凝结了人类的智慧和劳动，被人们生产出来的，那么，这些产品最开始都是出现在人类的大脑中。&lt;/p>
&lt;blockquote>
&lt;p>蜘蛛的活动与织工的活动相似，蜜蜂建筑蜂房的本领使人间的许多建筑师感到惭愧。但是，最蹩脚的建筑师从一开始就比最灵巧的蜜蜂高明的地方，是他在建筑蜂房以前，已经在自己的头脑中把它建成了。&lt;/p>
&lt;/blockquote>
&lt;p>一开始，我们要思考——这些即将被我们制造出来的汽车，它们满足了哪些人的哪些需要？它们应该是什么形状，它们应该具备哪些功能？对此，我们进行了一些想象和假设，有了一个模糊的蓝图。&lt;br>
接着，我们对生产过程进行规划和分工，我们设计出产品的原型，建设生产线，估计各种零件制造和组装的工时和损耗等，我们规划这些过程并安排相应的任务，追踪进度和问题。&lt;br>
随后，生产线被打造出来，零件被车铣、打磨，组装成型，成为完整的汽车。&lt;br>
我们将这些运输到世界各地，最终交付到了客户手中。&lt;br>
但这还没有结束——如果我们想要业务持续地进行下去并增长地话。&lt;br>
我们要为客户维修故障车辆，我们要聆听客户的抱怨以及他们新的、更深层的需要，我们总结这批汽车的优点和缺陷，我们继续进行新的市场调查和技术研究，然后打造更快，更舒适，更安全的新的汽车。&lt;/p>
&lt;h2 id="应用的生命周期">应用的生命周期&lt;/h2>
&lt;p>类似的，应用的生命周期通常有着如下几个阶段：&lt;/p>
&lt;ol>
&lt;li>计划。在这个阶段，我们收集用户需求，对应用的功能和形态进行假设和描绘，设计产品原型。拆解开发任务，评估任务的开发成本和难度，规划任务的优先级和排期，追踪任务的进度和开发过程中出现的缺陷。&lt;/li>
&lt;li>开发。这个阶段中，我们进行应用的编码和测试等工作，最终生成可部署的制品。&lt;/li>
&lt;li>交付。应用开发完成后，我们要将其部署到生产环境，配置相应的基础设施，如服务器和数据库等，直到用户能够使用到它。&lt;/li>
&lt;li>运维。应用交付后，我们需要对其进行观察和维护，如果它出现了故障，我们需要进行响应处理。&lt;/li>
&lt;/ol>
&lt;p>&lt;img src="http://suraciii.github.io/build-better-apps/1.png" alt="">&lt;/p>
&lt;p>而对于绝大多数现代应用来说，无论是web服务还是客户端应用，它们都是需要持续进行迭代和改进的，一个版本上线后，我们总是会不断地收集或者开发到更多的用户需求，我们会不断地识别到其中隐藏着的商业空间和发展潜力，我们会不断地尝试对其调整，以响应市场的变化，也会不断地进行改进，以图拓宽用户群体和商业渠道，或是为了应对来自竞争对手的压力。&lt;/p>
&lt;p>&lt;img src="http://suraciii.github.io/build-better-apps/2.png" alt="">&lt;/p>
&lt;p>而应用的每一次改进和调整，也都有着上面讲的四个阶段，形成一个迭代周期，这样，应用的生产成为了一个多周期的、持续性的活动。&lt;/p>
&lt;p>&lt;img src="http://suraciii.github.io/build-better-apps/3.png" alt="">&lt;/p>
&lt;p>在这样的活动中，在不断的改进和调整中，产品的价值不断增长，业务更加成功，而这正是我们所追求的。&lt;/p>
&lt;p>&lt;img src="http://suraciii.github.io/build-better-apps/4.png" alt="">&lt;/p>
&lt;h2 id="恶性循环和黑天鹅">恶性循环和黑天鹅&lt;/h2>
&lt;p>然而真的有这么乐观吗？来看看现实中的情况吧：&lt;/p>
&lt;ul>
&lt;li>工期评估是否足够&lt;strong>准确&lt;/strong>？计划是否总是被意外打乱？&lt;/li>
&lt;li>新功能需要多久时间才能够完全上线？在这期间出现过多少次&lt;strong>返工&lt;/strong>？&lt;/li>
&lt;li>我们多久可以进行一次&lt;strong>部署&lt;/strong>？部署总是可以顺利进行吗？&lt;/li>
&lt;li>线上产品出现过多少次在开发阶段没有测试出来的&lt;strong>缺陷&lt;/strong>？&lt;/li>
&lt;li>线上产品出现过多少次&lt;strong>服务中断&lt;/strong>？我们花费了多少时间来定位问题？又花了多少时间使其恢复正常？&lt;/li>
&lt;li>花费大量人力和时间投入打造的新功能，是否被客户所接受？是否具备与成本相符合的&lt;strong>价值&lt;/strong>？&lt;/li>
&lt;li>&lt;strong>变更&lt;/strong>是否很可能会导致失败？是否经常会破坏已有的功能？团队是否已经开始恐惧对产品进行变更？&lt;/li>
&lt;li>团队能花费多少力气在新功能的开发交付上？又有多少力气用在了不停地修复不断产生的问题？&lt;/li>
&lt;li>如果我们扩充团队，团队的生产力能随之有效增长吗？&lt;/li>
&lt;/ul>
&lt;p>思考清楚这些问题后，再看：&lt;/p>
&lt;ul>
&lt;li>我们能够对变化莫测的市场及时做出有效的响应吗？&lt;/li>
&lt;li>竞争对手们呢？&lt;/li>
&lt;/ul>
&lt;p>软件开发中存在着一个常见地恶性循环：&lt;/p>
&lt;ol>
&lt;li>新功能的开发总是会难以避免地在代码和基础设施中引入混乱，如果不及时进行干预，这些混乱会使得软件和基础设施变得越来越复杂和脆弱。&lt;/li>
&lt;li>复杂和脆弱的代码及基础设施，导致了更高的开发难度，更高的返工率，以及线上产品更高的故障率，也使得我们的任务和成本预估变得更加不准确。&lt;/li>
&lt;li>我们花费了更多的资源用来调查和修复问题，而新功能的开发又会需要更高的资源投入，为了满足工期要求，我们不得不暂时（我们是这么说服自己的）地去快而脏地处理故障和进行新的开发，从而引入了更多的混乱。&lt;/li>
&lt;/ol>
&lt;blockquote>
&lt;p>所有事情都变得更加困难——所有人都越来越忙，工作所消耗的时间越来越多，沟通变得更加缓慢，工作积压得越来越多。我们的工作耦合得更加紧密，即使是很小的行动也会导致较大的事故，我们更加害怕和拒绝做出变更。工作需要更多的沟通、协调和审批；团队必须等待更长的时间，等待相关的工作完成；我们的工作质量持续恶化。车轮开始嘎嘎作响地缓慢移动，要想使之继续转动，就需要付出更多的努力。&lt;/p>
&lt;/blockquote>
&lt;p>最终，黑天鹅出现了：&lt;/p>
&lt;p>&lt;img src="http://suraciii.github.io/build-better-apps/5.png" alt="">&lt;/p>
&lt;p>也许是一个政策的变更，也许是一次疫情的发生，或者是一个新生的更有活力的竞争对手的崛起，总之，灾难似乎是在慢慢地逼近，又仿佛在一瞬间降临，一个产品迎来了自己的终点。
也许企业会开发出新的应用，会去追求新的商机，团队也会有新的项目，或者有新的东家，但是这个应用的一切都死亡了。&lt;/p>
&lt;p>这个产品结束了，我们失败了。&lt;/p>
&lt;h2 id="改变状况的三个关键">改变状况的三个关键&lt;/h2>
&lt;p>如何避免这样的结局呢？这其中有三个关键点：&lt;/p>
&lt;h3 id="1-缩短交付周期">1. 缩短交付周期：&lt;/h3>
&lt;p>更短的交付周期意味着能够更快更及时更有效地获得来自客户的反馈，这有助于我们发掘客户的真实需要并去实现这些需求。
而更短的交付周期里，我们的交付计划能够做到更为准确，每次交付过程中的风险也会相对较小，出现的问题也更容易处理。
最终，更短的交付周期使得我们能够更迅捷、更频繁、更准确地向客户交付更多的价值。&lt;/p>
&lt;p>从：&lt;br>
&lt;img src="http://suraciii.github.io/build-better-apps/3.png" alt="">&lt;br>
到：&lt;br>
&lt;img src="http://suraciii.github.io/build-better-apps/6.png" alt="">&lt;/p>
&lt;h3 id="2-建立快速高效持续的反馈机制">2. 建立快速、高效、持续的反馈机制：&lt;/h3>
&lt;p>在应用交付的每个阶段里，我们建立快速、高效、持续的反馈机制，缩短问题检测周期，一方面，这可以帮助我们更及时准确地发现问题，从而以更低的成本实现更及时快速的修复，另一方面，也帮助我们打造安全可靠且高质量的应用。&lt;/p>
&lt;h3 id="3-持续学习和持续改善">3. 持续学习和持续改善&lt;/h3>
&lt;p>通过持续地，制度性地学习和改善，提高团队技能水平，将局部的经验快速转化为全局的改进，帮助整个组织尝试和实践新技术，通过科学的方式改进流程和开发产品，从成功和失败中积累经验教训，持续不断地进行改善，从而提高产品质量和生产力。&lt;/p>
&lt;h2 id="一些实践方法和工具">一些实践、方法和工具&lt;/h2>
&lt;p>具体来说，会有多种实践方法和工具来帮助我们做到这些：&lt;/p>
&lt;h3 id="1-持续集成">1. 持续集成&lt;/h3>
&lt;p>频繁持续地将个人的代码变更集成到主干分支，能够避免解决冲突成本过高，bug难以修复，开发者之间代码互相影响或重复相同工作等。
持续集成流水线中的自动化测试能够帮助我们在更早的阶段发现和解决问题，并避免问题在将来被重复引入。
自动化代码质量检查能够持续地帮助我们改善代码质量，减少代码中的混乱和隐患。&lt;/p>
&lt;h3 id="2-持续交付">2. 持续交付&lt;/h3>
&lt;p>通过高效、可靠、自动化的发布流水线，减少应用交付流程中的人工和停滞环节，降低过程中的阻力和风险，从而使应用可以更频繁、轻松地进行发布。&lt;/p>
&lt;h3 id="3-建立应用可观测性">3. 建立应用可观测性&lt;/h3>
&lt;p>为应用建立可观测性，提供完善的日志收集、链路追踪和监控能力，使开发者能够更好的理解应用内部的行为，从而减少应用故障的发现和定位所需要的时间，提高线上可用性。
完善的监控也提供了基于线上应用的反馈回路，能够在故障恶化或产生严重影响之前提前发现，也能够通过对用量指标的收集为应用的后续增强和改善提供信息。&lt;/p>
&lt;h3 id="4-技术债务管理">4. 技术债务管理&lt;/h3>
&lt;p>通过持续性地、组织性地、制度性的对技术债务进行管理，降低应用代码中存在的风险，减少新功能开发时可能导致的额外成本。&lt;/p>
&lt;h3 id="5-代码评审">5. 代码评审&lt;/h3>
&lt;p>通过代码评审，增强业务知识和技术知识在团队成员之间传播，增强团队成员的生产力，减少bug出现的风险，提高代码质量，获得可能的更优解决方案等。&lt;/p>
&lt;h3 id="6-基础设施即代码">6. 基础设施即代码&lt;/h3>
&lt;p>通过以代码形式管理幂等、不可变的基础设施，解决应用发布过程中因环境偏移（如随时间发展各个环境中的配置逐渐变得不同）而导致的各种问题，降低应用交付过程中的阻碍和风险。
同时，基础设施即代码也提高了管理基础设施的可靠性和效率等。&lt;/p>
&lt;h3 id="7-待续">7. 待续&lt;/h3>
&lt;p>&lt;em>引用：&lt;/em>&lt;/p>
&lt;p>&lt;em>1. The DevOps Handbook&lt;/em>&lt;br>
&lt;em>2. &lt;a href="https://azure.microsoft.com/en-us/overview/what-is-devops/">What is DevOps?&lt;/a>&lt;/em>&lt;br>
&lt;em>3. State Of DevOps 2021&lt;/em>&lt;/p></description></item><item><title>解决吞吐性能问题时的思路</title><link>http://suraciii.github.io/posts/throughput-issue-solutions/</link><pubDate>Fri, 20 Nov 2020 00:00:00 +0000</pubDate><guid>http://suraciii.github.io/posts/throughput-issue-solutions/</guid><description>&lt;h2 id="什么是throughput">什么是Throughput&lt;/h2>
&lt;p>Throughput指的是应用处理任务的速率，它所描述的是应用在单位时间内能够处理多大数量的任务&lt;/p>
&lt;p>如下，如果应用能够在1s中处理3个task，我们可以说它的throughput是3tps&lt;/p>
&lt;p>&lt;img src="https://fulu-item11-zjk.oss-cn-zhangjiakou.aliyuncs.com/images/1.png" alt="1">&lt;/p>
&lt;p>值得注意的是，throughput这个指标所代表的是速率，它并不代表同时性（Concurrency），比如图一中的3tps的应用，我们能说它可以在1s中处理3个task，但是并不意味着3个task是同时被处理的，而可能是顺序、线性地被处理&lt;/p>
&lt;p>如果应用可以支持同时处理多个任务，比如应用（系统）中有2个worker，每个worker都可以并行地在1s中内处理3个task，它的throughput则是6tps&lt;/p>
&lt;p>&lt;img src="https://fulu-item11-zjk.oss-cn-zhangjiakou.aliyuncs.com/images/2.png" alt="2">&lt;/p>
&lt;p>如何提高throughput呢？显然可以想到：&lt;/p>
&lt;ol>
&lt;li>缩短每个任务处理的耗时&lt;/li>
&lt;li>让更多的任务可以被同时处理 - 增加并行能力&lt;/li>
&lt;/ol>
&lt;p>下图中的应用（系统）可以支持同时处理3个任务，并且每个任务的处理耗时缩短到一半，其throughput是18tps&lt;/p>
&lt;p>&lt;img src="https://fulu-item11-zjk.oss-cn-zhangjiakou.aliyuncs.com/images/3.png" alt="3">&lt;/p>
&lt;p>##并行中的共享资源和锁&lt;/p>
&lt;p>如果对任务的处理需要访问/修改共享资源呢？比如在扣减库存的任务中，每个任务都需要去访问（校验）当前库存余量，并且要修改（扣减）它&lt;/p>
&lt;p>对共享资源的并发访问和修改会产生冲突和一致性问题，比如有两个扣减库存的任务正在同时进行，此时库存余量为1，两个任务都从存储中拿到了当前的库存余量，当其中一个任务完成后，库存余量被扣减为0，此时另一个任务已经完成了校验过程，再去扣减库存的时候，库存余量就被更新成了-1&lt;/p>
&lt;p>我们通常使用锁来解决对共享资源的争用所导致的并发冲突与一致性问题，使用资源锁来隔离对资源的操作，保证数据的一致性（正确性）&lt;/p>
&lt;p>&lt;img src="https://fulu-item11-zjk.oss-cn-zhangjiakou.aliyuncs.com/images/4.png" alt="4">&lt;/p>
&lt;p>如图，在试图使用某个资源之前，先获取锁从而占用住这个资源，隔离掉其它任务对此资源的访问/修改，从而在占用时间里保证资源的一致性，再使用结束后则释放锁，使资源可以被其它任务访问&lt;/p>
&lt;p>为了避免并发冲突以及获取一致性，并非一定要通过锁，也会有其它的方法（比如原子操作），但是总体上还是在对资源的访问/修改制造隔离&lt;/p>
&lt;p>隔离的后果是什么呢？&lt;/p>
&lt;h3 id="锁共享资源的争用和等待">锁（共享资源）的争用和等待&lt;/h3>
&lt;p>&lt;img src="https://fulu-item11-zjk.oss-cn-zhangjiakou.aliyuncs.com/images/5.png" alt="5">&lt;/p>
&lt;p>争用会导致wait time&lt;/p>
&lt;p>也因为我们对资源的访问/修改进行了隔离，导致了多个任务的处理无法同时使用共享资源，每个任务都要等待其它任务对资源的占用结束后才可以继续进行处理，这个等待就会产生wait time&lt;/p>
&lt;p>这些wait time意味着：&lt;/p>
&lt;ol>
&lt;li>任务的处理时间被延长 - 体现为latency&lt;/li>
&lt;li>并行的任务越多，wait time越长 - 破坏了并行处理任务的能力&lt;/li>
&lt;/ol>
&lt;h4 id="降低锁的成本">降低锁的成本&lt;/h4>
&lt;h5 id="降低使用锁的费用">降低使用锁的费用&lt;/h5>
&lt;p>锁的创建、获取、释放和销毁都是有代价的，降低使用锁本身的费用，比如把数据库锁换成redis锁，甚至换成本地内存锁&lt;/p>
&lt;p>以减库存为例： 提前把库存放到redis里，从redis中扣减&lt;/p>
&lt;h5 id="降低锁的占用时间">降低锁的占用时间&lt;/h5>
&lt;p>在获取到资源锁之后，应该尽快地释放它，尽量不要在占用锁的期间里做比较花费时间的事情，比如：1）发送HTTP请求 2）执行昂贵的SQL语句 3）超时等待 等等&lt;/p>
&lt;p>但是它有局限，如果我们尝试增加任务的并行数，wait time就会继续随之增长&lt;/p>
&lt;p>&lt;img src="https://fulu-item11-zjk.oss-cn-zhangjiakou.aliyuncs.com/images/6.png" alt="6">
&lt;img src="https://fulu-item11-zjk.oss-cn-zhangjiakou.aliyuncs.com/images/6-1.png" alt="6-1">&lt;/p>
&lt;h4 id="使用更细粒度的锁共享资源">使用更细粒度的锁（共享资源）&lt;/h4>
&lt;p>通过尽量使用更细粒度的锁（共享资源），可以使锁争用（碰撞）的概率更低，出现等待的情况也就更少&lt;/p>
&lt;p>&lt;img src="https://fulu-item11-zjk.oss-cn-zhangjiakou.aliyuncs.com/images/7.png" alt="7">&lt;/p>
&lt;p>以减库存为例： 把库存分布到多个篮子里，100=10*10，随机或者按策略去某个篮子里扣减，这样原本是所有任务都使用单一的库存余量，现在变成分散地使用10个库存余量，出现等待的概率就会变少&lt;/p>
&lt;p>无论是降低锁成本还是降低锁粒度，其目的都是减少争用的发生，减少任务的wait time，从而可以提高对多任务的并行处理能力&lt;/p>
&lt;h3 id="缓冲请求合并任务批量处理buffer-merge-process">缓冲请求，合并任务，批量处理（Buffer-Merge-Process）&lt;/h3>
&lt;p>&lt;img src="https://fulu-item11-zjk.oss-cn-zhangjiakou.aliyuncs.com/images/8.png" alt="8">&lt;/p>
&lt;p>以减库存为例：&lt;/p>
&lt;ol>
&lt;li>把减库存请求丢进队列中&lt;/li>
&lt;li>每次从队列中取出多个减库存请求，合并成一个减库存任务&lt;/li>
&lt;li>处理合并后的减库存任务&lt;/li>
&lt;/ol>
&lt;p>这种方式会导致单个任务的耗时增加 - 因为任务不会立即被处理，但是可以增加总体的throughput，某种程度上是用延迟交换了吞吐，需要考虑这个交换是否值得&lt;/p>
&lt;h4 id="总体思路">总体思路&lt;/h4>
&lt;p>1.首先定位争用&lt;/p>
&lt;p>2.减少争用，减少Wait Time&lt;/p>
&lt;p>3.最后才尝试Buffer-Merge-Process&lt;/p>
&lt;p>通常这三个方法都可以尝试，都有着一些成本和副作用，也经常需要结合使用，但是在考虑解决方案时，优先考虑解决锁争用&lt;/p>
&lt;p>共享资源争用是个很糟糕的质量信号，即使在当前看起来它没有产生很严重的后果，但是实际上它有着非常大的隐患&lt;/p>
&lt;p>它会导致应用在性能上变得脆弱：我们可以通过减少锁的费用和占用时间来减少争用从而提高性能，相反的，当锁的费用上升以及占用时间增加时，很容易大量争用导致性能急剧下降，而这时想要解决性能问题很可能要付出非常大的成本 。比如网络环境变化导致使用锁时的延迟增高，又或者一个业务需求或者bugfix需要你在占用锁时执行一个昂贵的sql语句或者http请求，甚至可能只是一个轻微的网络波动，都可能导致应用的吞吐剧烈下降&lt;/p>
&lt;h4 id="资源争用下的scalability问题">资源争用下的Scalability问题&lt;/h4>
&lt;p>当我们在开发应用的时候，对于应用的吞吐性能可以有三种要求：&lt;/p>
&lt;ol>
&lt;li>够用就行，只要能满足当前需求即可&lt;/li>
&lt;li>吞吐性能不仅要够用，还要出色，比如当前业务只需要我们的应用有30tps，但是我们在设计和开发时，要以1000tps的性能质量来要求它&lt;/li>
&lt;li>当前的吞吐性能需要满足当前的业务需求，不要求应用具备过高的吞吐性能，但是要求在将来它可以通过较低的成本来提升到更高的吞吐性能&lt;/li>
&lt;/ol>
&lt;p>第三种要求实际上就是对于应用的scalability的要求，它不要求过高的吞吐性能，但是它需要应用能够快速地响应业务需求对于吞吐性能要求的提升&lt;/p>
&lt;p>即当外部环境变化时 - 比如业务规模的增长，比如一个重要的feature带来了性能的降低，比如云迁移导致了应用运行环境发生了变化，这时我们需要能够通过调配资源能够简单快速的提升应用的吞吐性能来适应新的需求，先快速地做到&amp;quot;Doing more&amp;quot;，然后再去&amp;quot;With less&amp;quot;&lt;/p></description></item><item><title>愚钝程序员的生存之道 - Part0: 复杂性</title><link>http://suraciii.github.io/posts/how-to-survive-as-an-01x-developer-0/</link><pubDate>Wed, 22 Apr 2020 00:00:00 +0000</pubDate><guid>http://suraciii.github.io/posts/how-to-survive-as-an-01x-developer-0/</guid><description>&lt;p>工作几年，我发现自己身上有着一些现象：&lt;/p>
&lt;p>别人讲给我的东西要讲很多遍我才能理解&lt;/p>
&lt;p>学习技术要花很多时间才能掌握&lt;/p>
&lt;p>写代码平均每写十几行就会引入一个错误&lt;/p>
&lt;p>…&lt;/p>
&lt;p>这些现象似乎都指向着一个现实——我是一个愚钝的程序员。&lt;/p>
&lt;p>作为一个愚钝的程序员，想要产出平均水平的质量和产量从而生存下去，又不想被无尽的加班和焦头烂额吞噬自己的生活，就不得不掌握一些属于愚钝程序员的生存之道，从而可以不用很辛苦很累也可以交付出高质量的软件。&lt;/p>
&lt;h2 id="从复杂到复杂性">从复杂到复杂性&lt;/h2>
&lt;p>愚钝程序员在开发活动中总是面临诸多的挑战，这些挑战让愚钝程序员们感到自己愚钝，当我：&lt;/p>
&lt;ul>
&lt;li>总是难以搞明白一些代码是如何工作的&lt;/li>
&lt;li>总是需要花费很长时间来实现一个很小的改进&lt;/li>
&lt;li>或者总是不清楚自己应该去修改代码的哪些地方来实现这些改进&lt;/li>
&lt;li>总是难以快速修复一个bug&lt;/li>
&lt;li>或者总是难以在修复一个bug的同时而不引入另一个bug&lt;/li>
&lt;/ul>
&lt;p>当这一系列的状况发生，让我感觉自己无能为力去轻松解决问题，让我感觉自己难以处理，无从下手，让我怀疑自己是否不适合这个行业的时候，我发出了抱怨：&lt;/p>
&lt;p>——“这太复杂(Complex/Complicated)了！”&lt;/p>
&lt;h3 id="区分complex和complicated">区分Complex和Complicated&lt;/h3>
&lt;p>Complex与Complicated，二者所描述的对象都是是由存在大量互相交互的元素构成的系统，但是二者有着一些细微的不同之处：&lt;/p>
&lt;p>对于Complicated系统，它有着确定性(deterministic)，尽管系统中所有的组件都在发生交互，都在影响着系统的状态，但是这种交互是确定的，可测的，可靠的，并且系统被影响后的状态也是有限的、有界的&lt;/p>
&lt;p>而对于Complex系统，组件的交互以及对系统的影响是不确定的，系统的可能状态也是无限的、无界的&lt;/p>
&lt;p>对于Complex与Complicated，目前我还没有见到一个准确而又权威的定义，有时这两个词汇在不同领域甚至会被用来表达截然相反的两个概念，但是为了方便交流，在这里我们引用了上面这种定义，并且利用一个说法来帮助我们更清晰地识别Complex：&lt;/p>
&lt;p>&lt;em>Complex更偏向于将对象系统作为待解决的问题描述，即当我们使用Complex来描述一个系统时，Complex其实是在描述其投射在我们的大脑中的问题，那个我们正在尝试解决，并且无法轻松地理解处理的问题&lt;/em>&lt;/p>
&lt;h3 id="复杂性">复杂性&lt;/h3>
&lt;p>我们将复杂问题中那些标志其成为复杂问题的要素称作复杂性(Complexity) - 问题系统之所以复杂，正是因为其表现出了复杂性&lt;/p>
&lt;p>结合前面的分析，我们可以说：我们解决问题时所面对的复杂性，成为了我们对复杂问题的开发处理难度&lt;/p>
&lt;p>也就是说，当我们感觉问题杂乱、庞大，难以理解和处理的时候，我们大概是撞上了问题的复杂性&lt;/p>
&lt;p>&lt;img src="http://suraciii.github.io/how-to-survive-as-an-01x-developer-0/1.png" alt="1">&lt;/p>
&lt;h2 id="管理复杂性">管理复杂性&lt;/h2>
&lt;h3 id="撞上复杂性">撞上复杂性&lt;/h3>
&lt;p>面对复杂性，我们通常会有这几种反应：&lt;/p>
&lt;ol>
&lt;li>无视它，我们欺骗自己，假装复杂性并不存在。这种反应体现在我们会对系统做出一些假设，来忽略复杂性，一个经典的例子就是&lt;a href="https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing">Fallacies of distributed computing&lt;/a>，分布式系统中的网络通讯是极其常见的复杂性的来源，但是许多时候我们都会去假设网络是可靠安全稳定的&lt;/li>
&lt;li>通过启发探索(heuristic)，即调查(Probe)-感知(Sense)-响应(Respond)，这种方式也可以说是通过本能去应对——我们一步步地试探着前进，运气好的话也许可以积累一些有用经验形成本能来加速这个过程&lt;/li>
&lt;/ol>
&lt;p>在大多数情况下，人们面对复杂性时的反应都会是这两种，本质上这两种应对方式都是被动地应对，对于第一种我们可以略过不提，而第二种反应——愚钝的程序员在这条路上无法走得更远&lt;/p>
&lt;p>如果我们把一个复杂问题比作一个大泡泡，里面充满了复杂性，那么我们通过启发探索应对复杂性，就是去对问题进行探索和开发，由于学习理解能力、记忆力以及经验的差距，对于那些自身具备优秀的先天条件（学习理解能力、记忆力等）聪慧的程序员(Rockstar developer)，和那些在特定项目或特定领域上浸淫已久获得了丰富经验的地头蛇来说，这不是个很辛苦的过程，但是对于愚钝程序员来说，这里是个不公平的竞技场，一些对于愚钝程序员来说很复杂的问题，对于这些人来说却相对简单&lt;/p>
&lt;p>所以面对复杂性，愚钝的程序员要多考虑第三种应对方式&lt;/p>
&lt;h3 id="抓住复杂性的缰绳">抓住复杂性的缰绳&lt;/h3>
&lt;p>相比于被动地用本能去应对复杂性，作为人类的我们，更应该主动地去认识，识别，分析，从而有效地管理它&lt;/p>
&lt;h4 id="复杂性的来源">复杂性的来源&lt;/h4>
&lt;p>想要管理复杂性，首先就要知道在软件开发的活动中，我们所面对的复杂性&lt;strong>来源&lt;/strong>是哪里&lt;/p>
&lt;p>首先是来自现实世界的复杂性——我们开发软件是为了解决现实世界的问题，所以软件的开发必然会引入现实世界的复杂性（一些情况下我们会把它们称做“需求”）&lt;/p>
&lt;p>来自现实世界的复杂性是必要的复杂性，大多是作为开发者的我们无法控制的——经济危机可能导致公司的业务方向发生变化，孩子气的用户总是以我们预想不到的方式使用软件，GDPR，英国脱欧……这些都是我们无法改变又不可抗拒的，因为现实世界就是这么运作的&lt;/p>
&lt;p>但是作为开发者，除了来自现实世界的复杂性，我们还要面对软件本身的复杂性——随意懒散的建模，混乱的架构设计、千奇百怪的工具和框架、分布式系统的一致性问题甚至迥异的代码风格，都是开发者需要面对的&lt;/p>
&lt;p>这两种复杂性并不总是泾渭分明，通常，开发者沟通着现实世界与软件，接收来自现实的复杂性，混合进自己的理解，又通过代码输入到解决方案之中，最终又成为开发者自己需要面对的问题&lt;/p>
&lt;p>&lt;img src="http://suraciii.github.io/how-to-survive-as-an-01x-developer-0/2.png" alt="2">&lt;/p>
&lt;p>现实世界是必要的复杂，但是我们软件不必复杂，软件系统也许甚至经常会是complicated，但是不必complex。&lt;strong>软件是来自开发者的极其自由的创作&lt;/strong>，我们将数百万离散的元素聚合到一起，生成新的东西，它没有来自现实世界的诸多干扰和限制，我们无法通过Pull Request来改变现实世界的物理规律，但是我们可以任意去改变我们的软件，因此我们的软件的复杂性在大多数情况下都是可以控制的&lt;/p>
&lt;h3 id="发现复杂性">发现复杂性&lt;/h3>
&lt;p>我们无法和看不见的敌人战斗&lt;/p>
&lt;p>前面提到过当我们觉得问题难以理解，难以处理的时候，说明我们很有可能正在面对问题的复杂性，那么更具体一些，软件的复杂性会以怎样的形式体现呢？&lt;/p>
&lt;p>尽管软件系统的复杂性会表现为开发者的开发难度，但是具体地来讲，软件的复杂性会体现为三种形式&lt;/p>
&lt;h4 id="1-改动扩散change-amplification">1. 改动扩散(Change amplification)&lt;/h4>
&lt;p>改动扩散是指一个看起来很简单的改动，却需要对软件的多个不同的地方进行代码修改，这种修改被我们称为散弹式修改，它不仅仅意味着劳动量的增加，它所导致的更严重的问题在于，如果一个开发者想要进行这个改动，他就必须要清楚地知道所有需要修改的地方，并且还要清楚地知道这些地方都应该怎么修改，一旦开发者缺乏这些需要的信息和知识，或者是没有充分地理解它们，就极易引入错误&lt;/p>
&lt;h4 id="2-认知负担cognitive-load">2. 认知负担(Cognitive load)&lt;/h4>
&lt;p>认知负担是指开发者为了完成一个任务，需要了解多少东西，更高的认知负担意味着开发者们需要花费更多的时间去学习所需要的信息，并且有更高的因为缺乏信息导致的错误风险。&lt;/p>
&lt;p>可以看到改动扩散会导致某种程度上的认知负担（当然，认知负担不总是来源于改动扩散，而是一切可能导致开发者们理解困难的东西）&lt;/p>
&lt;h4 id="3-未知的无知unknown-unknown">3. 未知的无知(Unknown unknown)&lt;/h4>
&lt;p>未知的无知（我不确定我有没有翻译好）是指在你想要完成一个任务时，根本不知道应该去修改那些代码，根本不知道你该具备哪些信息，它意味着你有一些需要了解学习的信息，但是你在开发时根本无法发现它们是什么，甚至你根本没有发现你需要了解学习这些，直到之后有bug出现，你才能以回顾的方式发现它们&lt;/p>
&lt;p>未知的无知是最糟糕的，它是那些我们无法利用启发探索去到达的地方，而我们却只能以启发探索的方式应对它——因为我们根本不知道它的存在&lt;/p>
&lt;p>这是复杂性会体现为的三种形式，我们也可以将这三种形式作为复杂性的信号对待——当它们出现时，我们就要警惕了&lt;/p>
&lt;p>而观察这三种形式，可以明显地看到，它们的本质都是体现为开发者信息的匮乏，收集学习必要的信息会拖慢我们的开发，遗漏必要的信息会导致错误风险的增高&lt;/p>
&lt;h3 id="未知和不确定性">未知和不确定性&lt;/h3>
&lt;p>这些信息匮乏的现象是如何产生的呢？原因总体上来自于我们对软件系统的未知和其本身的不确定性&lt;/p>
&lt;p>软件系统的不确定性，导致了我们开发软件时所需要了解的信息爆炸，我们需要处理的状况也会增加，而我们对软件系统的未知，在导致我们需要收集额外信息的同时，也容易使我们在开发软件时做出错误的假设——可以说这是一种因无知而产生的傲慢&lt;/p>
&lt;p>&lt;img src="http://suraciii.github.io/how-to-survive-as-an-01x-developer-0/3.png" alt="3">&lt;/p>
&lt;p>所以，管理软件系统复杂性的基本方向，就是通过一系列的手段减少开发时的未知，捕获其中的不确定性，最终&lt;strong>打破迷雾&lt;/strong>，让复杂的问题在我们看来变得一目了然（Obvious）&lt;/p>
&lt;h2 id="关于这篇分享">关于这篇分享&lt;/h2>
&lt;ul>
&lt;li>这篇分享里的想法最初来自于对朋友抛出的一个问题“为什么我们要避免循环依赖”的持续发散的思考，结合了一些知识的阅读学习，对一些现象的观察，以及一些从实践中总结的规律，到现在对于这个问题总算是能够给出一个能够说服我自己的答案了&lt;/li>
&lt;li>当然，观点来自于理解，理解来自于经验，由于每个人的经历不同，很可能每个人的观点和理解也都有所不同，我也无法确定自己的理解是否是足够客观的，普适的，是能够通过正确认识问题从而解决问题的，所以非常希望大家都能分享自己的理解，我也能够通过和大家的交流，有进一步的理解，从而可以不断修正和完善自己的结论&lt;/li>
&lt;li>这篇是一系列相关分享的第一篇，计划是分享一系列我认为可以提高交付效率和质量，简化开发负担的工具和方法，但是因为这些分享是建立在我对软件开发和其复杂性的理解上的，所以这篇作为第一篇，说一下我的思路，为什么会这么想，后续（如果不鸽的话），我会分享一些更为具体的，可操作的工具和方法&lt;/li>
&lt;/ul>
&lt;h4 id="管理复杂性需要团队合作">管理复杂性需要团队合作&lt;/h4>
&lt;p>复杂性是由所有的开发者每人每个提交一点一滴的积累起来的——每个人都容易说服自己引入一点点的复杂性不是什么大事，但复杂性持续地在积累中增殖，最终成为软件灾难（&lt;a href="https://en.wikipedia.org/wiki/Big_ball_of_mud">大泥球&lt;/a>）&lt;/p>
&lt;p>&lt;strong>软件发展为复杂软件（大泥球）是团队合作的产物，所以也需要团队的力量才能真正解决它&lt;/strong>&lt;/p>
&lt;h4 id="软件复杂性不只是开发者的敌人">软件复杂性不只是开发者的敌人&lt;/h4>
&lt;p>尽管软件的高复杂性会加重开发者们的负担，但是它不止对开发者们造成伤害，对于项目本身，软件复杂性也是非常危险的，它会拖慢软件的交付效率，降低软件的交付质量，&lt;strong>失控的软件复杂性是项目过于脆弱的体现&lt;/strong>，持续下去会越来越无法承受挑战的冲击
&lt;em>如果要讨论这个问题，那对象系统就不是软件本身而是整个工程项目了，所以不在此进行深入分析&lt;/em>&lt;/p>
&lt;h5 id="参考">&lt;em>参考&lt;/em>：&lt;/h5>
&lt;ol>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=pMfzxmCzThI">Antifragile Designing the Systems of the Future - Barry O&amp;rsquo;Reilly - DDD Europe 2019&lt;/a>&lt;/li>
&lt;li>Cynefin framework &lt;a href="https://en.wikipedia.org/wiki/Cynefin_framework">https://en.wikipedia.org/wiki/Cynefin_framework&lt;/a>&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://www.infoq.com/articles/software-is-synthetic">The Fundamental Truth behind Successful Development Practices: Software is Synthetic&lt;/a>&lt;/strong>
- 非常好的一篇文章，讲清楚了“当我们在开发软件时，我们究竟在做什么”&lt;/li>
&lt;li>&lt;strong>&lt;a href="https://www.goodreads.com/en/book/show/39996759-a-philosophy-of-software-design">A Philosophy of Software Design&lt;/a>&lt;/strong>
- 这个分享中有很大一部分内容都是参考的这本书，我还没看完，但是就现在的体会而言，非常值得一看&lt;/li>
&lt;/ol></description></item><item><title>高并发下的高频账号余额加减方案探索</title><link>http://suraciii.github.io/posts/hot-spot-balance-reduce/</link><pubDate>Thu, 07 Mar 2019 00:00:00 +0000</pubDate><guid>http://suraciii.github.io/posts/hot-spot-balance-reduce/</guid><description>&lt;h2 id="问题描述">问题描述&lt;/h2>
&lt;p>打造一个服务，管理用户余额（信用点、积分、代币等），实现主要功能：&lt;/p>
&lt;ul>
&lt;li>加减款：即对余额进行增减&lt;/li>
&lt;li>冻结流程：减用户余额 加用户的冻结余额，同时生成一条冻结记录&lt;/li>
&lt;li>付款流程：减付款用户的冻结余额，加收款商户（可能为多个）的余额&lt;/li>
&lt;li>余额流水：余额的每笔变动都会产生相应流水明细&lt;/li>
&lt;/ul>
&lt;p>同时 还有以下特征：&lt;/p>
&lt;ul>
&lt;li>高并发&lt;/li>
&lt;li>多数用户均为高频账号&lt;/li>
&lt;li>强一致性&lt;/li>
&lt;/ul>
&lt;h2 id="代码层面事务与锁">代码层面：事务与锁&lt;/h2>
&lt;p>问题中存在的若干规则&lt;/p>
&lt;ul>
&lt;li>冻结与减款（减用户余额）时，校验减后余额&lt;/li>
&lt;li>付款（减用户冻结余额）时，校验减后冻结余额&lt;/li>
&lt;li>冻结时，更新余额、更新冻结余额、生成冻结记录&lt;/li>
&lt;li>付款时，各账号加减余额、冻结余额、解冻、生成付款记录&lt;/li>
&lt;/ul>
&lt;h3 id="锁的优化">锁的优化&lt;/h3>
&lt;p>总体来看，需要加锁的地方有：1)更新余额 2)解冻(更改冻结状态)&lt;/p>
&lt;p>主要拿更新余额来说，最直观的流程：&lt;/p>
&lt;ul>
&lt;li>加锁查询余额&lt;/li>
&lt;li>检查余额&lt;/li>
&lt;li>更新余额&lt;/li>
&lt;/ul>
&lt;p>即&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sql" data-lang="sql">&lt;span style="color:#66d9ef">SELECT&lt;/span> &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#66d9ef">FROM&lt;/span> &lt;span style="color:#f92672">`&lt;/span>Accounts&lt;span style="color:#f92672">`&lt;/span> &lt;span style="color:#66d9ef">WHERE&lt;/span> &lt;span style="color:#f92672">`&lt;/span>Id&lt;span style="color:#f92672">`=@&lt;/span>Id &lt;span style="color:#66d9ef">FOR&lt;/span> &lt;span style="color:#66d9ef">UPDATE&lt;/span>;
&lt;span style="color:#75715e">/* 检查余额 */&lt;/span>
&lt;span style="color:#66d9ef">Update&lt;/span> &lt;span style="color:#f92672">`&lt;/span>Accounts&lt;span style="color:#f92672">`&lt;/span> &lt;span style="color:#66d9ef">SET&lt;/span> &lt;span style="color:#f92672">`&lt;/span>Balance&lt;span style="color:#f92672">`=@&lt;/span>Balance;
&lt;/code>&lt;/pre>&lt;/div>&lt;p>由于“多数用户均为高频账号”，在高频校验更新余额时势必会产生性能问题，而在某些特殊场景下，甚至会产生死锁的问题&lt;/p>
&lt;p>那么这里的主要思路就是减少降低锁的使用频率：&lt;/p>
&lt;h4 id="a-只在减款校验时加锁">a) 只在减款校验时加锁&lt;/h4>
&lt;p>余额的更新中，只有减款时需要校验当前实时余额，而加款则不需要&lt;/p>
&lt;p>减款时流程不变，加款时直接对余额进行加操作&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sql" data-lang="sql">&lt;span style="color:#66d9ef">Update&lt;/span> &lt;span style="color:#f92672">`&lt;/span>Accounts&lt;span style="color:#f92672">`&lt;/span> &lt;span style="color:#66d9ef">SET&lt;/span> &lt;span style="color:#f92672">`&lt;/span>Balance&lt;span style="color:#f92672">`=@&lt;/span>Balance&lt;span style="color:#f92672">+@&lt;/span>Amount;
&lt;/code>&lt;/pre>&lt;/div>&lt;h4 id="b-先减款再校验">b) 先减款，再校验&lt;/h4>
&lt;p>加款操作去掉了锁，减款是否也能去掉呢？
我们在减款中加锁，是为了避免在减款操作时余额被并发更改，出现校验时账号有充足的余额，但是减款时余额却变成了负数
如果我们按照之前的流程 加锁-查询-更新，的确是需要锁住这一行记录，但是如果先减款，再判断余额是否小于0，就可以避免锁的需求&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-sql" data-lang="sql">&lt;span style="color:#66d9ef">Update&lt;/span> &lt;span style="color:#f92672">`&lt;/span>Accounts&lt;span style="color:#f92672">`&lt;/span> &lt;span style="color:#66d9ef">SET&lt;/span> &lt;span style="color:#f92672">`&lt;/span>Balance&lt;span style="color:#f92672">`=@&lt;/span>Balance&lt;span style="color:#f92672">-@&lt;/span>Amount RETURNING &lt;span style="color:#f92672">`&lt;/span>Balance&lt;span style="color:#f92672">`&lt;/span>;
&lt;span style="color:#75715e">/* 判断Balance是否小于0，如果小于0，则回滚事务 */&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这样在减款操作时也避免了显式锁行&lt;/p>
&lt;p>解冻校验也可以用类似方法，比如将冻结记录的校验与更新，使用&lt;code>WHERE&lt;/code>语句合成一条SQL语句，来避免锁的使用&lt;/p>
&lt;h3 id="尝试摆脱数据库事务">尝试摆脱数据库事务&lt;/h3>
&lt;p>上一步里去除了更新余额时的显式行锁，但是对于高频账号来说，数据库事务自带的锁/隔离机制仍然会是其并发性能的一大阻碍
但是在需要多个写（更新、插入）操作同时成功同时回滚的场景下，数据库的强一致性事务似乎又是不可或缺的&lt;/p>
&lt;p>那么可以换一种思路：
只要保证所有操作&lt;em>最终&lt;/em>一定会成功，那么是否就可以去除对数据库事务的依赖了呢？&lt;/p>
&lt;p>看上面几个流程
首先单纯的加减款肯定是可以不依赖数据库事务的，那么就是冻结、付款等需要多次写操作的场景
比如冻结场景，要么 1.减款成功，生成冻结 2.减款失败，不生成冻结
减款失败的情况不需要担心，但是如果减款成功的情况下，需要保证一定有对应的一条冻结记录插入&lt;/p>
&lt;p>如何保证？
可以在生成冻结失败时，重试此操作，直到最终生成成功为止
但是我们可能不止需要重试冻结失败的操作，在程序异常中止然后重启后，有些情况下我们无从得知上次异常中止的流程中，是否已经进行了减款操作，失去了数据库事务两阶段提交(2PC)支持，我们只能重试整个冻结流程，即1.减款成功，生成冻结&lt;/p>
&lt;p>这里就有很严重一个问题，此时减款操作的重试是不安全的，每次减款，都是更新账号上的余额字段，这就需要一个幂等机制，来让减款可以安全地重试&lt;/p>
&lt;h4 id="eventsourcing">EventSourcing&lt;/h4>
&lt;p>如果了解&lt;a href="https://docs.microsoft.com/en-us/azure/architecture/patterns/event-sourcing">EventSourcing&lt;/a>的话，接下来的事情就顺理成章了&lt;/p>
&lt;p>还记得需求中关于流水明细的部分吗？&lt;/p>
&lt;p>参考EventSourcing的实现，可以把每次的余额更新操作，都转换成相关的流水明细的插入操作，而插入操作是很容易实现幂等的，同时，大多数情况下，插入记录的性能要比更新记录的性能要好&lt;/p>
&lt;p>实现非常简单，即在进行加减款操作时，不更新数据库中的余额字段，而是向数据库中插入一条变动记录，如账号XXX余额减10
如何进行减款前的校验呢？我们可以预先把某账号的流水记录预先读取出来，然后将此账号的余额按照流水记录走过一遍，就在内存中得到了当前的余额，同时在插入变动记录时，同时更新内存中的余额值，当然，要保证内存中的余额变动和流水中一致&lt;/p>
&lt;h5 id="分布式">分布式？&lt;/h5>
&lt;p>前面说过，要保证内存中的余额和数据库中的流水记录一致，如果是单实例的应用，很简单，只需要创造一个单例的账号对象，并保证其余额不会被并发更新就好了，但是如果是分布式的应用怎么办？&lt;/p>
&lt;p>如何在分布式系统中避免并发冲突？和许多分布式EventSourcing框架一样，此时，Actor是唯一解决方案。Actor模型提供了&lt;em>针对每个Actor(账号)的单线程执行约束&lt;/em>，也就是说，每个账号作为Actor存在于集群中时，其代码执行是不会有并发冲突的&lt;/p>
&lt;h5 id="看起来很完美">看起来很完美？&lt;/h5>
&lt;p>实际上不是，无论是EventSourcing还是Actor模型，都不是常规的编程思想，其实现无疑会比较复杂，并且在分布式环境中，对其不够熟悉的话，很容易踩入各种各样的并发陷阱 - 当然这些陷阱在常规分布式应用中也是普遍存在的，但是在这里更容易令人疏忽大意&lt;/p>
&lt;p>并且，Actor的&lt;em>单线程执行约束&lt;/em>，本身也是并发性能的一个阻碍&lt;/p>
&lt;h2 id="高频账号问题">高频账号问题&lt;/h2>
&lt;p>在代码层面提高高频账号或者单点账号的单操作性能，从而提高其并发性能，但是在这条路上想走得更远是十分困难的。
或许可以以一个更大的视角来尝试解决&lt;/p>
&lt;p>高频账号问题，本质上其实相当类似秒杀/减库存问题
所以很大程度上，可以借用秒杀/减库存问题的解决方案&lt;/p>
&lt;h3 id="拆分高频账号">拆分高频账号&lt;/h3>
&lt;p>一个思路是将高频账号拆分为多个子账号（资金池），加减款时随机找一个子账号扣款
但是和秒杀/减库存不同，在资金的加减上，拆分子账号会引入许多问题：&lt;/p>
&lt;ol>
&lt;li>如何调度平衡各个子账号之间的资金？&lt;/li>
&lt;li>流水无法记录变动前后的总余额&lt;/li>
&lt;li>扣款时如果一个子账号的余额不够，需要扣多个子账号怎么办？&lt;/li>
&lt;/ol>
&lt;p>想到这里，除非整个业务体系能改造，我已经基本放弃此方案了&lt;/p>
&lt;h3 id="批量提交与异步">批量提交与异步&lt;/h3>
&lt;p>批量提交与异步，是提高单点吞吐量的绝佳法宝，比如很多数据库都有通过批量commit事务来提高吞吐量&lt;/p>
&lt;p>回到问题本身，资金的变动分为a)加款 b)减款&lt;/p>
&lt;p>对于加款，它属于必定会成功的操作，可以直接把它丢进一个&lt;em>可靠的&lt;/em>队列里去执行
出队时，缓冲若干个加款命令，合并成一个批量提交&lt;/p>
&lt;p>而减款是有可能会失败的（余额不足），我们需要一个手段把减款的结果通知给请求方&lt;/p>
&lt;p>如果请求是同步的（如HTTP请求），我们只能挂起相应的HTTP请求，等到扣款有结果了再唤醒，返回响应，但是这种在分布式系统中实现起来会非常麻烦
相反，如果能够将接口改造成为异步的话，实现起来就比较简单了&lt;/p>
&lt;ol>
&lt;li>接到扣款请求&lt;/li>
&lt;li>将请求添加进队列，并直接返回响应，表示已收到请求&lt;/li>
&lt;li>请求方主动查询请求结果，或处理方回调通知结果&lt;/li>
&lt;/ol>
&lt;p>这种实现并不怎么合适，因为有时上游调用方需要根据调用的结果来决定下一步的流程，比如冻结成功后才能发起付款，如果失败则需要告知用户/管理员等
所以也许使用一个异步的事件系统来控制整个业务流程会比较合适
但是这就是后话了&lt;/p></description></item><item><title>为Kubernetes集群添加用户</title><link>http://suraciii.github.io/posts/add-user-for-k8s/</link><pubDate>Wed, 29 Aug 2018 00:00:00 +0000</pubDate><guid>http://suraciii.github.io/posts/add-user-for-k8s/</guid><description>&lt;h2 id="kubernetes中的用户">Kubernetes中的用户&lt;/h2>
&lt;p>K8S中有两种用户(User)——服务账号(ServiceAccount)和普通意义上的用户(User)&lt;br>
ServiceAccount是由K8S管理的，而User通常是在外部管理，K8S不存储用户列表——也就是说，添加/编辑/删除用户都是在外部进行，无需与K8S API交互，虽然K8S并不管理用户，但是在K8S接收API请求时，是可以认知到发出请求的用户的，实际上，所有对K8S的API请求都需要绑定身份信息(User或者ServiceAccount)，这意味着，可以为User配置K8S集群中的请求权限&lt;/p>
&lt;h3 id="有什么区别">有什么区别？&lt;/h3>
&lt;p>最主要的区别上面已经说过了，即ServiceAccount是K8S内部资源，而User是独立于K8S之外的。从它们的本质可以看出：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>User通常是人来使用，而ServiceAccount是某个服务/资源/程序使用的&lt;/p>
&lt;/li>
&lt;li>
&lt;p>User独立在K8S之外，也就是说User是可以作用于全局的，在任何命名空间都可被认知，并且需要在全局唯一&lt;br>
而ServiceAccount作为K8S内部的某种资源，是存在于某个命名空间之中的，在不同命名空间中的同名ServiceAccount被认为是不同的资源&lt;/p>
&lt;/li>
&lt;li>
&lt;p>K8S不会管理User，所以User的创建/编辑/注销等，需要依赖外部的管理机制，K8S所能认知的只有一个用户名
ServiceAccount是由K8S管理的，创建等操作，都通过K8S完成&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>这里说的添加用户指的是普通意义上的用户，即存在于集群外的用户，为k8s的使用者。&lt;br>
实际上叫做添加用户也不准确，用户早已存在，这里所做的只是使K8S能够识别此用户，并且控制此用户在集群内的权限&lt;/p>
&lt;h2 id="用户验证">用户验证&lt;/h2>
&lt;p>尽管K8S认知用户靠的只是用户的名字，但是只需要一个名字就能请求K8S的API显然是不合理的，所以依然需要验证此用户的身份
在K8S中，有以下几种验证方式：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>X509客户端证书&lt;br>
客户端证书验证通过为API Server指定&lt;code>--client-ca-file=xxx&lt;/code>选项启用，API Server通过此ca文件来验证API请求携带的客户端证书的有效性，一旦验证成功，API Server就会将客户端证书Subject里的CN属性作为此次请求的用户名&lt;/p>
&lt;/li>
&lt;li>
&lt;p>静态token文件&lt;br>
通过指定&lt;code>--token-auth-file=SOMEFILE &lt;/code>选项来启用bearer token验证方式，引用的文件是一个包含了 token,用户名,用户ID 的csv文件
请求时，带上&lt;code>Authorization: Bearer 31ada4fd-adec-460c-809a-9e56ceb75269&lt;/code>头信息即可通过bearer token验证&lt;/p>
&lt;/li>
&lt;li>
&lt;p>静态密码文件&lt;br>
通过指定&lt;code>--basic-auth-file=SOMEFILE&lt;/code>选项启用密码验证，类似的，引用的文件时一个包含 密码,用户名,用户ID 的csv文件
请求时需要将&lt;code>Authorization&lt;/code>头设置为&lt;code>Basic BASE64ENCODED(USER:PASSWORD)&lt;/code>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>这里只介绍客户端验证&lt;/p>
&lt;h2 id="为用户生成证书">为用户生成证书&lt;/h2>
&lt;p>假设我们操作的用户名为tom&lt;/p>
&lt;ol>
&lt;li>
&lt;p>首先需要为此用户创建一个私钥&lt;br>
&lt;code>openssl genrsa -out tom.key 2048&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>接着用此私钥创建一个csr(证书签名请求)文件，其中我们需要在subject里带上用户信息(CN为用户名，O为用户组)&lt;br>
&lt;code>openssl req -new -key tom.key -out tom.csr -subj &amp;quot;/CN=tom/O=MGM&amp;quot;&lt;/code>&lt;br>
其中/O参数可以出现多次，即可以有多个用户组&lt;/p>
&lt;/li>
&lt;li>
&lt;p>找到K8S集群(API Server)的CA证书文件，其位置取决于安装集群的方式，通常会在&lt;code>/etc/kubernetes/pki/&lt;/code>路径下，会有两个文件，一个是CA证书(ca.crt)，一个是CA私钥(ca.key)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>通过集群的CA证书和之前创建的csr文件，来为用户颁发证书&lt;br>
&lt;code>openssl x509 -req -in tom.csr -CA path/to/ca.crt -CAkey path/to/ca.key -CAcreateserial -out tom.crt -days 365&lt;/code>&lt;br>
-CA和-CAkey参数需要指定集群CA证书所在位置，-days参数指定此证书的过期时间，这里为365天&lt;/p>
&lt;/li>
&lt;li>
&lt;p>最后将证书(tom.crt)和私钥(tom.key)保存起来，这两个文件将被用来验证API请求&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h2 id="为用户添加基于角色的访问控制rbac">为用户添加基于角色的访问控制(RBAC)&lt;/h2>
&lt;h3 id="角色role">角色(Role)&lt;/h3>
&lt;p>在RBAC中，角色有两种——普通角色(Role)和集群角色(ClusterRole)，ClusterRole是特殊的Role，相对于Role来说：&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Role属于某个命名空间，而ClusterRole属于整个集群，其中包括所有的命名空间&lt;/p>
&lt;/li>
&lt;li>
&lt;p>ClusterRole能够授予集群范围的权限，比如node资源的管理，比如非资源类型的接口请求(如&amp;quot;/healthz&amp;quot;)，比如可以请求全命名空间的资源(通过指定 &amp;ndash;all-namespaces)&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="为用户添加角色">为用户添加角色&lt;/h3>
&lt;h4 id="首先创造一个角色">首先创造一个角色&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Role&lt;/span>
&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">rbac.authorization.k8s.io/v1beta1&lt;/span>
&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;span style="color:#f92672">namespace&lt;/span>: &lt;span style="color:#ae81ff">a-1&lt;/span>
&lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">admin&lt;/span>
&lt;span style="color:#f92672">rules&lt;/span>:
- &lt;span style="color:#f92672">apiGroups&lt;/span>: [&lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>]
&lt;span style="color:#f92672">resources&lt;/span>: [&lt;span style="color:#e6db74">&amp;#34;*&amp;#34;&lt;/span>]
&lt;span style="color:#f92672">verbs&lt;/span>: [&lt;span style="color:#e6db74">&amp;#34;*&amp;#34;&lt;/span>]
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这是在a-1命名空间内创建了一个admin管理员角色，这里只是用admin角色举例，实际上如果只是为了授予用户某命名空间管理员的权限的话，是不需要新建一个角色的，K8S已经内置了一个名为admin的ClusterRole&lt;/p>
&lt;h4 id="将角色和用户绑定">将角色和用户绑定&lt;/h4>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">RoleBinding&lt;/span>
&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">rbac.authorization.k8s.io/v1beta1&lt;/span>
&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">admin-binding&lt;/span>
&lt;span style="color:#f92672">namespace&lt;/span>: &lt;span style="color:#ae81ff">a-1&lt;/span>
&lt;span style="color:#f92672">subjects&lt;/span>:
- &lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">User&lt;/span>
&lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">tom&lt;/span>
&lt;span style="color:#f92672">apiGroup&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
&lt;span style="color:#f92672">roleRef&lt;/span>:
&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">Role&lt;/span>
&lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">admin&lt;/span>
&lt;span style="color:#f92672">apiGroup&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>如yaml中所示，RoleBinding资源创建了一个 Role-User 之间的关系，&lt;code>roleRef&lt;/code>节点指定此RoleBinding所引用的角色，&lt;code>subjects&lt;/code>节点指定了此RoleBinding的受体，可以是User，也可以是前面说过的ServiceAccount，在这里只包含了名为 tom 的用户&lt;/p>
&lt;h4 id="添加命名空间管理员的另一种方式">添加命名空间管理员的另一种方式&lt;/h4>
&lt;p>前面说过，K8S内置了一个名为admin的ClusterRole，所以实际上我们无需创建一个admin Role，直接对集群默认的admin ClusterRole添加RoleBinding就可以了&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-yaml" data-lang="yaml">&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">RoleBinding&lt;/span>
&lt;span style="color:#f92672">apiVersion&lt;/span>: &lt;span style="color:#ae81ff">rbac.authorization.k8s.io/v1beta1&lt;/span>
&lt;span style="color:#f92672">metadata&lt;/span>:
&lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">admin-binding&lt;/span>
&lt;span style="color:#f92672">namespace&lt;/span>: &lt;span style="color:#ae81ff">a-1&lt;/span>
&lt;span style="color:#f92672">subjects&lt;/span>:
- &lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">User&lt;/span>
&lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">tom&lt;/span>
&lt;span style="color:#f92672">apiGroup&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
&lt;span style="color:#f92672">roleRef&lt;/span>:
&lt;span style="color:#f92672">kind&lt;/span>: &lt;span style="color:#ae81ff">ClusterRole&lt;/span>
&lt;span style="color:#f92672">name&lt;/span>: &lt;span style="color:#ae81ff">admin&lt;/span>
&lt;span style="color:#f92672">apiGroup&lt;/span>: &lt;span style="color:#e6db74">&amp;#34;&amp;#34;&lt;/span>
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这里虽然引用的是作为ClusterRole的admin角色，但是其权限被限制在RoleBinding admin-binding所处的命名空间，即a-1内
如果想要添加全命名空间或者说全集群的管理员，可以使用cluster-admin角色&lt;/p>
&lt;p>到此为止，我们已经：&lt;/p>
&lt;ul>
&lt;li>为tom用户提供了基于X509证书的验证&lt;/li>
&lt;li>为a-1命名空间创造了一个admin角色&lt;/li>
&lt;li>为用户tom和角色admin创建了绑定关系&lt;/li>
&lt;/ul>
&lt;h2 id="为kubectl配置用户">为kubectl配置用户&lt;/h2>
&lt;p>tom已经是管理员了，现在我们想要通过kubectl以tom的身份来操作集群，需要将tom的认证信息添加进kubectl的配置，即~/.kube/config中&lt;/p>
&lt;p>这里假设config中已经配置好了k8s集群&lt;/p>
&lt;ol>
&lt;li>
&lt;p>通过命令&lt;code>kubectl config set-credentials tom --client-certificate=path/to/tom.crt --client-key=path/to/tom.key&lt;/code>将用户tom的验证信息添加进kubectl的配置&lt;br>
此命令会在配置中添加一个名为tom的用户&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>kubectl config set-context tom@aliyun --cluster=aliyun --namespace=a-1 --user=tom&lt;/code>&lt;br>
此命令添加了一个context配置——设定使用aliyun集群，默认使用a-1命名空间，使用用户tom进行验证&lt;/p>
&lt;/li>
&lt;li>
&lt;p>在命令中带上 &lt;code>kubectl --context=tom@aliyun ...&lt;/code> 参数即可指定kubectl使用之前添加的名为tom@aliyun的context操作集群&lt;br>
也可以通过命令 &lt;code>kubectl config use-context tom@aliyun&lt;/code> 来设置当前使用的context&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h4 id="tips-将认证信息嵌入kubectl的配置中">Tips: 将认证信息嵌入kubectl的配置中&lt;/h4>
&lt;p>通过&lt;code>kubectl config set-credentials&lt;/code>命令添加的用户，其默认使用的是引用证书文件路径的方式，表现在~/.kube/config中，就是：&lt;/p>
&lt;pre tabindex="0">&lt;code>users:
- name: tom
user:
client-certificate: path/to/tom.crt
client-key: path/to/tom.key
&lt;/code>&lt;/pre>&lt;p>如果觉得这样总是带着两个证书文件不方便的话，可以将证书内容直接放到config文件里&lt;/p>
&lt;ol>
&lt;li>
&lt;p>将tom.crt/tom.key的内容用BASE64编码&lt;br>
&lt;code>cat tom.crt | base64 --wrap=0&lt;/code>&lt;br>
&lt;code>cat tom.key | base64 --wrap=0&lt;/code>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>将获取的编码后的文本复制进config文件中&lt;/p>
&lt;/li>
&lt;/ol>
&lt;pre tabindex="0">&lt;code>users:
- name: ich
user:
client-certificate-data: ...
client-key-data: ...
&lt;/code>&lt;/pre>&lt;p>这样就不再需要证书和私钥文件了，当然这两个文件还是保存起来比较好&lt;/p>
&lt;p>&lt;em>参考资料：&lt;/em>&lt;br>
&lt;em>&lt;a href="https://kubernetes.io/docs/reference/access-authn-authz/authentication/">Authenticating - Kubernetes Docs&lt;/a>&lt;/em>&lt;br>
&lt;em>&lt;a href="https://docs.bitnami.com/kubernetes/how-to/configure-rbac-in-your-kubernetes-cluster/">Configure RBAC in your Kubernetes Cluster&lt;/a>&lt;/em>&lt;br>
&lt;em>&lt;a href="https://kubernetes.io/docs/reference/access-authn-authz/rbac/">Using RBAC Authorization - Kubernetes Docs&lt;/a>&lt;/em>&lt;br>
&lt;em>&lt;a href="https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#config">Kubectl Reference Docs#config&lt;/a>&lt;/em>&lt;br>
&lt;em>&lt;a href="https://brancz.com/2017/10/16/kubernetes-auth-x509-client-certificates/">Kubernetes auth: X509 client certificates&lt;/a>&lt;/em>&lt;/p></description></item><item><title>Pipelines - .NET中的新IO API指引(二)</title><link>http://suraciii.github.io/posts/trans-pipelines-marcgravell-2/</link><pubDate>Tue, 17 Jul 2018 00:00:00 +0000</pubDate><guid>http://suraciii.github.io/posts/trans-pipelines-marcgravell-2/</guid><description>&lt;p>原文：&lt;a href="https://blog.marcgravell.com/2018/07/pipe-dreams-part-2.html">Pipelines - a guided tour of the new IO API in .NET, part 2&lt;/a>&lt;/p>
&lt;p>作者：marcgravell&lt;/p>
&lt;p>在&lt;a href="https://blog.marcgravell.com/2018/07/pipe-dreams-part-1.html">上一章&lt;/a>，我们讨论了以往的&lt;code>Stream&lt;/code>API中存在的一些问题，并且介绍了&lt;code>Pipe&lt;/code>,&lt;code>PipeWriter&lt;/code>,&lt;code>PipeReader&lt;/code> 等API，研究如何写出一个&lt;code>Pipe&lt;/code> 并且从中消费数据，我们也讨论了&lt;code>FlushAsync()&lt;/code> 和&lt;code>ReadAsync()&lt;/code> 是如何协同保证两端的工作，从而解决“空”和“满”的场景——在没有数据时挂起reader，并在数据到来时恢复它；在写入快过读取(Pipe满载)时挂起writer，并在reader追上后恢复它；并且我们也在线程模型的层面上探讨了什么是“挂起”。&lt;/p>
&lt;p>在这章，我们将会研究pipelines的内存模型：数据实际上存在于哪里？。我们也会开始着手研究如何在现实场景中使用pipelines以满足真实需求。&lt;/p>
&lt;h3 id="内存模型我的数据在哪里">内存模型：我的数据在哪里？&lt;/h3>
&lt;p>在上一章，我们讲了pipe如何管理所有的缓冲区，允许writer通过 &lt;code>GetMemory()&lt;/code>和&lt;code>GetSpan()&lt;/code>请求缓冲区，随后通过&lt;code>ReadAsync()&lt;/code>中的 &lt;code>.Buffer&lt;/code> 将提交后的数据暴露给reader——reader取得的数据是一个 &lt;code>ReadOnlySequence&amp;lt;byte&amp;gt;&lt;/code>，即所有数据的几个片段。&lt;/p>
&lt;p>那么其中究竟发生了什么？&lt;/p>
&lt;p>每一个&lt;code>Pipe&lt;/code>实例都有一个引用指向&lt;code>MemoryPool&amp;lt;byte&amp;gt;&lt;/code>——一个&lt;a href="https://www.nuget.org/packages/System.Memory/">&lt;code>System.Memory&lt;/code>&lt;/a> 中的新东西，顾名思义，它创建了一个内存池。在创建&lt;code>Pipe&lt;/code>的时候，你可以在选项中指定一个专门的 &lt;code>MemoryPool&amp;lt;byte&amp;gt;&lt;/code>，但是在默认情况下(我猜也是大多数情况下)——应该是使用一个应用级别共享的 (&lt;code>MemoryPool&amp;lt;byte&amp;gt;.Shared&lt;/code>) 内存池。&lt;/p>
&lt;p>&lt;code>MemoryPool&amp;lt;byte&amp;gt;&lt;/code> 的概念是非常开放的。其&lt;em>默认&lt;/em>的实现是简单地使用&lt;code>ArrayPool&amp;lt;byte&amp;gt;.Shared&lt;/code> (应用级别的数组池)，在需要的时候租借数组，并在使用完后归还。这个 &lt;code>ArrayPool&amp;lt;T&amp;gt;&lt;/code> 使用了 &lt;code>WeakReference&lt;/code>来实现，所以池化的数组在内存有压力时是可以回收的，但是，当你请求&lt;code>GetMemory(someSize)&lt;/code> 或者 &lt;code>GetSpan(someSize)&lt;/code>时，它并不是简单地向内存池请求“someSize”，相反，它在内部追踪了一个“片段(segment)”，一个新“片段”将是（默认情况下，可以通过配置改变）someSize和2048字节中的最大值，这样请求一个大小可观的内存意味着我们的系统不会充满着许多小数组，而后者会对GC造成显著碰撞。当你在writer中 &lt;code>Advance(bytesWritten)&lt;/code>，它：&lt;/p>
&lt;ul>
&lt;li>移动一个表达当前已使用多少片段的内部计数器&lt;/li>
&lt;li>更新reader的”备读(available to be read)“链的末端；如果我们刚刚对一个空片段的第一个字节进行了写入，这意味着将会向链中增加一个新片段，否则，它意味着当前链的结尾标志被增加（后移）&lt;/li>
&lt;/ul>
&lt;p>这就是我们从 &lt;code>ReadAsync()&lt;/code>中获取到的”备读“链；而当我们在reader中 &lt;code>AdvanceTo&lt;/code> ——如果整个片段都被消费掉了，那么pipe会将这些片段送回内存池。在那里，它们可以被多次复用。并且作为上述两点导致的直接结果，我们可以看到在大多数情况下(即使在writer中多次调用&lt;code>Advance&lt;/code> )，我们最终可以在reader中发现一个单独的片段；而在片段边界处，或reader落后于writer，数据开始累积的情况下，会有多个片段。&lt;/p>
&lt;p>只有使用默认池才能：&lt;/p>
&lt;ul>
&lt;li>我们不用在每次调用&lt;code>GetMemory()&lt;/code> / &lt;code>GetSpan()&lt;/code>时都要分配内存&lt;/li>
&lt;li>我们不需要每次&lt;code>GetMemory()&lt;/code> / &lt;code>GetSpan()&lt;/code>都要有一个单独的数组——通常我们只是获得同样的”片段“中的某个不同的范围&lt;/li>
&lt;li>只使用少量的大缓冲数组&lt;/li>
&lt;li>它们不需要大量的类库代码，就可以自动回收&lt;/li>
&lt;li>当不再需要时，它们可以被GC回收&lt;/li>
&lt;/ul>
&lt;p>这也解释了为什么在&lt;code>GetMemory()&lt;/code> / &lt;code>GetSpan()&lt;/code>中请求少量空间再在之后检查其大小的举动是有效的：我们可以访问&lt;em>当前段的剩下未使用的部分&lt;/em>。这意味着：一个大小为2048的片段，在之前的写入中用掉了200字节——即使我们只请求5字节，我们也可以看到我们还剩下1848字节可供使用，或者更多——记住：从&lt;code>ArrayPool.Shared&lt;/code> 中获取到的数组也是一个”至少这么大“的操作。&lt;/p>
&lt;h3 id="零复制缓冲区">零复制缓冲区&lt;/h3>
&lt;p>在此还有需要注意的地方是，我们获取数据缓冲的时候，&lt;em>没有进行任何数据的复制&lt;/em>。writer申请一个缓冲区，然后第一次写入数据到需要的位置。这就成了writer和reader之间的缓冲区，无需复制数据。而如果reader当前无法处理完所有的数据，它能够通过显示声明其”未被消费“地方式将数据放回pipe。这样无需为reader维护一个单独的数据积压处，而这在使用&lt;code>Stream&lt;/code>的协议处理代码中是&lt;em>非常&lt;/em>常见的。&lt;/p>
&lt;p>正是这种功能间的组合使得pipeline代码在内存层面显得非常友好。你可以用&lt;code>Stream&lt;/code>做到所有的这些，但是却需要大量令人痛苦的易出错的代码去实现，如果你想做好，甚至需要更多——并且你几乎必须去为每个场景单独地实现它。Pipelines让良好的内存处理变为默认的简单的途径——落入成功之中&lt;/p>
&lt;h3 id="更多奇特的内存池">更多奇特的内存池&lt;/h3>
&lt;p>你并不受限于使用我们之前讨论的内存池；你可以实现你自己的自定义内存池！默认内存池的优点在于它很简单。尤其是我们是否100%完美地返回每个片段并不重要——如果我们以某种方式丢弃某个pipe，最坏的情况会是GC将在某个时刻回收掉被丢弃的片段。它们不会回到池中，但那没关系。&lt;/p>
&lt;p>但是，你可以做很多有趣的东西。想象一下，比如一个 &lt;code>MemoryPool&amp;lt;byte&amp;gt;&lt;/code>承载巨量的内存——通过一些非常大的数组得到的托管内存，或是通过 &lt;code>Marshal.AllocHGlobal&lt;/code> 获得的非托管内存（注意 &lt;code>Memory&lt;/code> 和 &lt;code>Span&lt;/code> 并&lt;em>不受限于&lt;/em>数组——它们需要的不过是某种连续内存），按需使用这些巨大的内存块。这有很大的潜在场景，但是它会使片段的可靠回收变得更加重要。大多数系统不应该这么做，但是提供这样的灵活性是好的。&lt;/p>
&lt;h3 id="在真实系统中有用的pipes">在真实系统中有用的pipes&lt;/h3>
&lt;p>我们在第一部分中用的例子，是一个读写均在同一代码的单独&lt;code>Pipe&lt;/code>。很明显这不是个真实场景（除非我们是在试图模拟一个&amp;quot;echo&amp;quot;服务器），所以我们在更真实的场景中可以做什么呢？首先，我们需要把我们的pipelines连接到什么东西上。我们通常并不想单独地使用Pipe，相反，我们希望可以有一个&lt;em>结合一个普遍的系统或API使用&lt;/em>的pipe。所以，来让我们开始看看接下来会是什么样子吧。&lt;/p>
&lt;p>在这里，我们需要注意：发布于.NET Core 2.1的pipelines不包括任何终端实现。这意味着： &lt;code>Pipe&lt;/code> 虽然存在，但是&lt;em>在框架内&lt;/em>没有提供任何的与现有系统的实际连接——就像提供了抽象的 &lt;code>Stream&lt;/code> 基类，却没有 &lt;code>FileStream&lt;/code>,，&lt;code>NetworkStream&lt;/code>等。是的，这听起来让人感到失望，但是这只是由于时间限制，不要慌！现在在进行一些关于它们应该以哪种优先级实现的“活跃的”讨论。并且现在有少量的社区贡献来补足最明显的缺陷。&lt;/p>
&lt;p>一旦我们处于那些场景，我们可能会问：“将pipelines连接到另一个数据后端需要什么？”&lt;/p>
&lt;p>也许将一个pipe连接到一个 &lt;code>Stream&lt;/code>会是一个不错的开头。我知道你在想：“但是Marc，你在上一章你不遗余力地再说 &lt;code>Stream&lt;/code> 有多么糟糕！”。我没有改变我的看法，它不一定是完美的——对于那些特定场景的&lt;code>Stream&lt;/code>实现（比如&lt;code>NetworkStream&lt;/code>或&lt;code>FileStream&lt;/code>）我们可以有一个专门的基于pipelines的终端直接与那个服务以最小的中转进行通讯；但是这是一个有用的起步：&lt;/p>
&lt;ul>
&lt;li>它使我们可以立即访问到巨量的API——任何可以通过&lt;code>Stream&lt;/code>暴露数据，或任何通过封装的streams作为中间层的API（加密、压缩等）&lt;/li>
&lt;li>它将所有老旧的&lt;code>Stream&lt;/code>API隐藏在一个明确清晰的表层下&lt;/li>
&lt;li>它带来了&lt;em>几乎所有&lt;/em>我们之前提到过的优点&lt;/li>
&lt;/ul>
&lt;p>所以，让我们开始吧！我们首先要思考的是：这里的&lt;em>方向&lt;/em>是什么？就像刚才提到的一样，&lt;code>Stream&lt;/code>是模糊不清的——可能只读，只写，或可读可写。来假设我们想解决的是最通常的问题：一个可读可写表现为双工行为的stream——这可以让我们访问如sockets(通过&lt;code>NetworkStream&lt;/code>)之类的东西。这意味着我们实际上将会需要&lt;em>两个&lt;/em>pipe——一个用来输入，一个用来输出。Pipelines通过明确地声明&lt;code>IDuplexPipe&lt;/code>接口来帮助我们指明道路。这是一个非常简单的接口，数据传输给&lt;code>IDuplexPipe&lt;/code>就像传输给两个pipe的端点一样——一个标记为&amp;quot;in&amp;quot;，一个标记为&amp;quot;out&amp;quot;：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="color:#66d9ef">interface&lt;/span> IDuplexPipe
{
PipeReader Input { &lt;span style="color:#66d9ef">get&lt;/span>; }
PipeWriter Output { &lt;span style="color:#66d9ef">get&lt;/span>; }
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>我们接下来想要做的是创建一个类来实现 &lt;code>IDuplexPipe&lt;/code>，但是其内部使用两个&lt;code>Pipe&lt;/code>实例：&lt;/p>
&lt;ul>
&lt;li>一个&lt;code>Pipe&lt;/code>会是输出缓冲区（从消费者的角度来看），它将会在调用者写入&lt;code>Output&lt;/code>是被填充——并且我们将会用一个循环来消费这个&lt;code>Pipe&lt;/code>并且将数据推入底层&lt;code>Stream&lt;/code>(被用来写入网络，或者其它任何stream可以写入的)&lt;/li>
&lt;li>一个&lt;code>Pipe&lt;/code>将会是输入缓冲区（从消费者的角度来看），我们将有一个循环来从底层&lt;code>Stream&lt;/code>&lt;em>读取&lt;/em>数据，并将其推入&lt;code>Pipe&lt;/code>，它将会在调用者从&lt;code>Input&lt;/code>中读取时排出&lt;/li>
&lt;/ul>
&lt;p>这个方法可以立即解决普遍影响着那些使用&lt;code>Stream&lt;/code>的人&lt;em>一大堆&lt;/em>的问题：&lt;/p>
&lt;ul>
&lt;li>我们现在有了input/output缓冲区，用于从读/写调用中解耦stream访问，而不用添加&lt;code>BufferedStream&lt;/code>或是其它类似的防止数据碎片的功能（对于写入代码来说）,并且这将会使我们在处理数据时很方便去接收更多数据（特别是对于读取代码来说，这样我们不用在请求更多数据时保持暂停）&lt;/li>
&lt;li>如果调用代码的写入快过stream的&lt;code>Write&lt;/code>可以处理的程度，背压特性将会展现出来，对调用代码进行节流，这样我们不会被充满未发送数据的巨大缓冲区所终结&lt;/li>
&lt;li>如果stream的&lt;code>Read&lt;/code>超过了消费这些数据的调用代码，背压特性也会在这里出场，对我们的stream读取循环进行节流，这样我们不会被充满未处理数据的巨大缓冲区所终结&lt;/li>
&lt;li>读取和写入代码都会受益于我们之前所讨论的内存池的所有优点&lt;/li>
&lt;li>调用代码从来不用担心数据的后备存储（未完成帧）等——pipe去解决它&lt;/li>
&lt;/ul>
&lt;h3 id="那么它看起来会是什么样">那么它看起来会是什么样？&lt;/h3>
&lt;p>基本上，我们需要做的就是这样：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="color:#66d9ef">class&lt;/span> &lt;span style="color:#a6e22e">StreamDuplexPipe&lt;/span> : IDuplexPipe
{
Stream &lt;span style="color:#ae81ff">_&lt;/span>stream;
Pipe &lt;span style="color:#ae81ff">_&lt;/span>readPipe, &lt;span style="color:#ae81ff">_&lt;/span>writePipe;
&lt;span style="color:#66d9ef">public&lt;/span> PipeReader Input =&amp;gt; &lt;span style="color:#ae81ff">_&lt;/span>readPipe.Reader;
&lt;span style="color:#66d9ef">public&lt;/span> PipeWriter Output =&amp;gt; &lt;span style="color:#ae81ff">_&lt;/span>writePipe.Writer;
&lt;span style="color:#75715e">// ... more here
&lt;/span>&lt;span style="color:#75715e">&lt;/span>}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>注意我们有两个不同的pipe；调用者获取每个pipe的一个端点——然后我们的代码将会操作每个pipe的&lt;em>另一个&lt;/em>端点。&lt;/p>
&lt;h3 id="对pipe进行抽取">对pipe进行抽取&lt;/h3>
&lt;p>那么我们与stream交互的代码是什么样的呢？像之前说过的那样，我们需要两个方法。首先——很简单——一个循环，从&lt;code>_stream&lt;/code>中读取数据并且将其推入&lt;code>_readPipe&lt;/code>，然后被调用代码所消费；这个方法的核心类似这样：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="color:#66d9ef">while&lt;/span> (&lt;span style="color:#66d9ef">true&lt;/span>)
{
&lt;span style="color:#75715e">// note we&amp;#39;ll usually get *much* more than we ask for
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> buffer = &lt;span style="color:#ae81ff">_&lt;/span>readPipe.Writer.GetMemory(&lt;span style="color:#ae81ff">1&lt;/span>);
&lt;span style="color:#66d9ef">int&lt;/span> bytes = &lt;span style="color:#66d9ef">await&lt;/span> &lt;span style="color:#ae81ff">_&lt;/span>stream.ReadAsync(buffer);
&lt;span style="color:#ae81ff">_&lt;/span>readPipe.Writer.Advance(bytes);
&lt;span style="color:#66d9ef">if&lt;/span> (bytes == &lt;span style="color:#ae81ff">0&lt;/span>) &lt;span style="color:#66d9ef">break&lt;/span>; &lt;span style="color:#75715e">// source EOF
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> flush = &lt;span style="color:#66d9ef">await&lt;/span> &lt;span style="color:#ae81ff">_&lt;/span>readPipe.Writer.FlushAsync();
&lt;span style="color:#66d9ef">if&lt;/span> (flush.IsCompleted || flush.IsCanceled) &lt;span style="color:#66d9ef">break&lt;/span>;
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这个循环向pipie请求一个缓冲区，然后用 &lt;code>netcoreapp2.1&lt;/code> 中&lt;code>Stream.ReadAsync&lt;/code> 的新重载接收一个 &lt;code>Memory&amp;lt;byte&amp;gt;&lt;/code> 来填充缓冲区——我们一会儿讨论如果你现在没有一个能接收 &lt;code>Memory&amp;lt;byte&amp;gt;&lt;/code> 的API该怎么办。当读取完成后，它使用&lt;code>Advance&lt;/code>向pipe提交这个数量的字节，然后它在pipe上调用 &lt;code>FlushAsync()&lt;/code> 来（如果需要的话）唤醒reader，或者在背压减轻时暂停写循环。注意我们还需要检查&lt;code>Pipe&lt;/code>的 &lt;code>FlushAsync()&lt;/code>的结果——它可以告诉我们pipe的消费者已经告知其已经读取完了所有想要的数据（&lt;code>Iscompleted&lt;/code>），或者pipe本身被关闭（&lt;code>IsCanceled&lt;/code>）。&lt;/p>
&lt;p>注意在这两种情况下，我们都希望确保在此循环退出时告诉管道，这样我们就不会最终在没有数据到来时永远在调用端等待下去。意外发生时，或者有时在调用 &lt;code>_stream.ReadAsync&lt;/code> （或其它方法）时，可能会有异常抛出，所以最好是利用&lt;code>try&lt;/code>/&lt;code>finally&lt;/code>：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">Exception error = &lt;span style="color:#66d9ef">null&lt;/span>;
&lt;span style="color:#66d9ef">try&lt;/span>
{
&lt;span style="color:#75715e">// our loop from the previous sample
&lt;/span>&lt;span style="color:#75715e">&lt;/span>}
&lt;span style="color:#66d9ef">catch&lt;/span>(Exception ex) { error = ex; }
&lt;span style="color:#66d9ef">finally&lt;/span> { &lt;span style="color:#ae81ff">_&lt;/span>readPipe.Writer.Complete(error); }
&lt;/code>&lt;/pre>&lt;/div>&lt;p>如果你愿意的话，你可以使用两个 &lt;code>Complete&lt;/code> ——一个在try末尾（成功时），一个在catch中（失败时）。&lt;/p>
&lt;p>我们需要的第二个方法会比较复杂。我们需要一个循环来从&lt;code>_writePipe&lt;/code>中消费数据，然后将其推入&lt;code>_stream&lt;/code>。核心代码会像这样：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="color:#66d9ef">while&lt;/span> (&lt;span style="color:#66d9ef">true&lt;/span>)
{
&lt;span style="color:#66d9ef">var&lt;/span> read = &lt;span style="color:#66d9ef">await&lt;/span> &lt;span style="color:#ae81ff">_&lt;/span>writePipe.Reader.ReadAsync();
&lt;span style="color:#66d9ef">var&lt;/span> buffer = read.Buffer;
&lt;span style="color:#66d9ef">if&lt;/span> (buffer.IsCanceled) &lt;span style="color:#66d9ef">break&lt;/span>;
&lt;span style="color:#66d9ef">if&lt;/span> (buffer.IsEmpty &amp;amp;&amp;amp; read.IsCompleted) &lt;span style="color:#66d9ef">break&lt;/span>;
&lt;span style="color:#75715e">// write everything we got to the stream
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">foreach&lt;/span> (&lt;span style="color:#66d9ef">var&lt;/span> segment &lt;span style="color:#66d9ef">in&lt;/span> buffer)
{
&lt;span style="color:#66d9ef">await&lt;/span> &lt;span style="color:#ae81ff">_&lt;/span>stream.WriteAsync(segment);
}
&lt;span style="color:#ae81ff">_&lt;/span>writePipe.AdvanceTo(buffer.End);
&lt;span style="color:#66d9ef">await&lt;/span> &lt;span style="color:#ae81ff">_&lt;/span>stream.FlushAsync();
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这会等待一些数据（可能在多个缓冲区里），然后进行一些退出判断检查；像之前一样，我们可以在&lt;code>IsCanceled&lt;/code>时放弃，但是下一个检查会比较微妙：我们不希望只因为&lt;em>producer&lt;/em>表示它们已经写入了所有想要的数据（&lt;code>Iscompleted&lt;/code>）就停止写入，不然我们也许会丢失它们末尾几段数据——我们需要继续直到我们已经写入了它们所有的数据，直到&lt;code>buffer.IsEmpty&lt;/code>。这是个简化后的例子，因为我们一直写入所有数据——我们之后会看到更复杂的例子。一旦我们有了数据，我们按顺序将每个非连续缓冲区写入stream中——因为&lt;code>Stream&lt;/code>一次只能写入一个缓冲区（同样，我使用的是&lt;code>netcoreapp2.1&lt;/code>中的重载，接受&lt;code>ReadOnlyMemory&amp;lt;byte&amp;gt;&lt;/code>参数，但是我们不限于此）。一旦它写完了缓冲区，它告诉pipe我们已经消费完了所有数据，然后刷新(flush)底层的&lt;code>Stream&lt;/code>。&lt;/p>
&lt;p>在“真实”代码中，我们&lt;em>也许&lt;/em>希望更积极地优化从而减少刷新底层stream直到我们知道再也不会有可读取地数据，也许 在&lt;code>_writePipe.Reader.ReadAsync()&lt;/code>之外可以使用&lt;code>_writePipe.Reader.TryRead(...)&lt;/code> 。这个方法地工作方式类似 &lt;code>ReadAsync()&lt;/code>但是保证会同步返回——用来测试“在我忙的时候writer是否附加了什么？”。但是上面的内容已经讲述了这一点。&lt;/p>
&lt;p>另外，像之前一样，我们也许需要添加一个 &lt;code>try&lt;/code>/&lt;code>finally&lt;/code>，这样在我们退出时总是会调用&lt;code>_writePipe.Reader.Complete()&lt;/code>。&lt;/p>
&lt;p>我们可以使用 &lt;code>PipeScheduler&lt;/code> 来启动这两个泵(pumps)，这会确保它们在预期环境中运行，然后我们的循环开始泵送数据。我们要添加&lt;em>一些&lt;/em>格外的内容（我们可能需要一种机制来 &lt;code>Close()&lt;/code>/&lt;code>Dispose()&lt;/code> 底层stream等）——但是像你所看到的，将 &lt;code>IDuplexPipe&lt;/code> 连接到没有pipeline设计的源不需要是一项&lt;em>艰巨&lt;/em>的任务。&lt;/p>
&lt;h3 id="这是我之前做的">这是我之前做的&amp;hellip;&lt;/h3>
&lt;p>我已经将上面的内容简化了一些（说真的，不是太多），以便让它适合讨论，但是你可能仍然不应该从这里复制粘贴代码来尝试让它工作。我并没有声称它们时适用于所有情况的完美解决方案，但是作为&lt;a href="https://github.com/StackExchange/StackExchange.Redis/issues/871">StackExchange.Redis 2.0版&lt;/a>工作的一部分，我们实现了一系列pipelines的绑定放在nuget上——毫无创意地命名为 &lt;code>Pipelines.Sockets.Unofficial&lt;/code> （&lt;a href="https://www.nuget.org/packages/Pipelines.Sockets.Unofficial/">nuget&lt;/a>,github(&lt;a href="https://github.com/mgravell/Pipelines.Sockets.Unofficial">https://github.com/mgravell/Pipelines.Sockets.Unofficial&lt;/a>)，它包括：&lt;/p>
&lt;ul>
&lt;li>将双工的&lt;code>Stream&lt;/code>转换为 &lt;code>IDuplexPipe&lt;/code> （就像上面说的）&lt;/li>
&lt;li>将只读&lt;code>Stream&lt;/code>转换为&lt;code>PipeReader&lt;/code>&lt;/li>
&lt;li>将只写&lt;code>Stream&lt;/code>转换为&lt;code>PipeWriter&lt;/code>&lt;/li>
&lt;li>将 &lt;code>IDuplexPipe&lt;/code> 转换为双工的&lt;code>Stream&lt;/code>&lt;/li>
&lt;li>将&lt;code>PipeReader&lt;/code>转换为只读&lt;code>Stream&lt;/code>&lt;/li>
&lt;li>将&lt;code>PipeWriter&lt;/code>转换为只写&lt;code>Stream&lt;/code>&lt;/li>
&lt;li>将&lt;code>Socket&lt;/code>直接转换成&lt;code>IDuplexPipe&lt;/code>（不经过&lt;code>NetworkStream&lt;/code>）&lt;/li>
&lt;/ul>
&lt;p>前六个在 &lt;code>StreamConnection&lt;/code>的静态方法中，最后一个在&lt;code>SocketConnection&lt;/code>里。&lt;/p>
&lt;p>&lt;code>StackExchange.Redis&lt;/code> 牵涉着大量&lt;code>Socket&lt;/code>工作，所以我们对如何将pipeline连接到socket上非常感兴趣，对于没有TLS的redis连接，我们可以直接将我们的&lt;code>Socket&lt;/code>连接到pipeline：&lt;/p>
&lt;ul>
&lt;li>&lt;code>Socket&lt;/code>  ⇔ &lt;code>SocketConnection&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>对于需要TLS的redis连接（比如云redis提供商），我们可以这样连接：&lt;/p>
&lt;ul>
&lt;li>&lt;code>Socket&lt;/code> ⇔ &lt;code>NetworkStream&lt;/code> ⇔ &lt;code>SslStream&lt;/code> ⇔ &lt;code>StreamConnection&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>所有这两种配置都是一个&lt;code>Socket&lt;/code>在其中一端，一个&lt;code>IDuplexPipe&lt;/code>在另一端，它开始展示我们如何将pipeline作为更复杂系统的一部分。也许更重要的是，它为我们在未来实施改变提供了空间。将来有可能的例子：&lt;/p>
&lt;ul>
&lt;li>Tim Seaward一直在折腾&lt;a href="https://github.com/Drawaes/Leto">&lt;code>Leto&lt;/code>&lt;/a>，它提供了不需要 &lt;code>SslStream&lt;/code> ，直接用&lt;code>IDuplexPipe&lt;/code>实现TLS的能力（并且不需要stream逆变器）&lt;/li>
&lt;li>在 Tim Seaward，David Fowler 和Ben Adams之间，有&lt;em>一系列&lt;/em>直接实现pipelines而不用托管sockets的实验性/正在进行的网络层工作，包括&amp;quot;libuv&amp;quot;，&amp;ldquo;RIO&amp;rdquo;（Registerd IO），和最近的&amp;quot;magma&amp;quot;——它将整个TCP栈推入用户代码从而减少系统调用。&lt;/li>
&lt;/ul>
&lt;p>看这个空间如何发展将会非常有趣！&lt;/p>
&lt;h3 id="但是我当前的api不会使用span或者memory">但是我当前的API不会使用 &lt;code>Span&lt;/code> 或者 &lt;code>Memory&lt;/code>！&lt;/h3>
&lt;p>当在写将数据从pipe中泵送到其它系统（比如一个&lt;code>Socket&lt;/code>）时，很有可能你会遇到不接收 &lt;code>Span&lt;/code> 或者 &lt;code>Memory&lt;/code>的API。不要慌，这没有大碍，你依然可以有很多种变通方案使其变得更……传统。&lt;/p>
&lt;p>在你有一个 &lt;code>Memory&lt;/code> 或者 &lt;code>ReadOnlyMemory&lt;/code>时，第一个技巧是&lt;code>MemoryMarshal.TryGetArray(...)&lt;/code>。它接收一个&lt;em>memory&lt;/em>并且尝试获取一个&lt;code>ArraySegment&lt;/code> ，它用一个&lt;code>T[]&lt;/code>vector和一个&lt;code>int&lt;/code>偏移/计数对描述相同的数据。显然，这只有在这块内存&lt;em>是基于&lt;/em>一个vector时才能用，而情况并非总是如此，所以这可能会在异种的内存池上失败。我们第二个解决办法时&lt;code>MemoryMarshal.GetReference(...)&lt;/code>，它接受一个&lt;em>span&lt;/em>然后返回一个原始数据起点的引用（实际上是一个“托管指针”，又叫做 &lt;code>ref T&lt;/code>）。一旦我们有了一个 &lt;code>ref T&lt;/code>，我们可以用&lt;code>unsafe&lt;/code>语法来获得一个这个数据的非托管指针，在这种情况下会有用：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">Span&amp;lt;&lt;span style="color:#66d9ef">byte&lt;/span>&amp;gt; span = ...
&lt;span style="color:#66d9ef">fixed&lt;/span>(&lt;span style="color:#66d9ef">byte&lt;/span>* ptr = &amp;amp;MemoryMarshal.GetReference(span))
{
&lt;span style="color:#75715e">// ...
&lt;/span>&lt;span style="color:#75715e">&lt;/span>}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>即使span的长度是零，你依然可以这么做，其会返回一个第0项&lt;em>将会存在&lt;/em>的位置，而且甚至在使用&lt;code>default&lt;/code>span即根本没有实际后备内存的时候，也可以这么使用。后面这个有一点需要注意，因为&lt;code>ref T&lt;/code>&lt;em>通常不被认为会是null&lt;/em>，但是在这里它是。实际上，只要你不去尝试对这种空引用进行解引用，不会有什么问题。如果你使用&lt;code>fixed&lt;/code>将其转换为一个非托管指针，你会得到一个空（零）指针，这相对来说更合理（并且在一些&lt;code>P/Invoke&lt;/code>场景中会有用），&lt;code>MemoryMarshal&lt;/code> 本质上是&lt;code>unsafe&lt;/code> 代码的同义词，即使你调用的那段代码并没有使用&lt;code>unsafe&lt;/code> 关键字。使用它是完全有效的，但是如果不恰当地使用它，它可能会坑到你——所以小心就是了。&lt;/p>
&lt;h3 id="pipe的应用端代码是什么样的">Pipe的应用端代码是什么样的？&lt;/h3>
&lt;p>OK，我们有了&lt;code>IDuplexPipe&lt;/code>，并且我们也看到了如何将两个pipe的“业务端”连接到你选择的后端数据服务。现在，我们在应用代码中如何使用它？&lt;/p>
&lt;p>按照我们上一章的例子，我们将从 &lt;code>IDuplexPipe.Output&lt;/code> 中把&lt;code>PipeWriter&lt;/code>传递给我们的出站代码，从 &lt;code>IDuplexPipe.Input&lt;/code> 中把 &lt;code>PipeReader&lt;/code> 传递给我们的入站代码。&lt;/p>
&lt;p>&lt;em>出站&lt;/em>代码相当简单，并且通常是需要直接从基于&lt;code>Stream&lt;/code>的代码移植成基于&lt;code>PipeWriter&lt;/code>的代码。关键的区别还是那样，即&lt;em>你不再手动控制缓冲区&lt;/em>。下面是一个一个典型的实现：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">ValueTask&amp;lt;&lt;span style="color:#66d9ef">bool&lt;/span>&amp;gt; Write(SomeMessageType message, PipeWriter writer)
{
&lt;span style="color:#75715e">// (this may be multiple GetSpan/Advance calls, or a loop,
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// depending on what makes sense for the message/protocol)
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> span = writer.GetSpan(...);
&lt;span style="color:#75715e">// TODO: ... actually write the message
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">int&lt;/span> bytesWritten = ... &lt;span style="color:#75715e">// from writing
&lt;/span>&lt;span style="color:#75715e">&lt;/span> writer.Advance(bytesWritten);
&lt;span style="color:#66d9ef">return&lt;/span> FlushAsync(writer);
}
&lt;/code>&lt;/pre>&lt;/div>&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> &lt;span style="color:#66d9ef">async&lt;/span> ValueTask&amp;lt;&lt;span style="color:#66d9ef">bool&lt;/span>&amp;gt; FlushAsync(PipeWriter writer)
{
&lt;span style="color:#75715e">// apply back-pressure etc
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> flush = &lt;span style="color:#66d9ef">await&lt;/span> writer.FlushAsync();
&lt;span style="color:#75715e">// tell the calling code whether any more messages
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// should be written
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">return&lt;/span> !(flush.IsCanceled || flush.IsCompleted);
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>Write&lt;/code> 的第一部分是我们的业务代码，我们需要把数据从writer写入到缓冲区；通常这会多次调用 &lt;code>GetSpan(...)&lt;/code> 和 &lt;code>Advance()&lt;/code>。当我们写完了数据，我们可以flush它从而保证启动泵送并且应用背压控制。对于那些非常大的消息体，我们&lt;em>也可以&lt;/em>在中间点flush，但是对于大多数场景：一个消息flush一次足够了。&lt;/p>
&lt;p>如果你好奇为什么我将&lt;code>FlushAsync&lt;/code> 分割到不同的代码中：那是因为我想&lt;code>await&lt;/code> &lt;code>FlushAsync&lt;/code>的结果来检查退出条件，所以它需要在一个&lt;code>async&lt;/code> 方法里，在这里最有效率的访问内存方式是通过 &lt;code>Span&amp;lt;byte&amp;gt;&lt;/code> API，&lt;code>Span&amp;lt;byte&amp;gt;&lt;/code> 是一个 &lt;code>ref struct&lt;/code> 类型，因此我们&lt;a href="https://github.com/dotnet/csharplang/blob/master/proposals/csharp-7.2/span-safety.md">不能在异步方法中将 &lt;code>Span&amp;lt;byte&amp;gt;&lt;/code> 作为局部变量使用&lt;/a>。一个实用的办法是简单地分割代码，这样一个方法做 &lt;code>Span&amp;lt;byte&amp;gt;&lt;/code> 工作，一个方法做&lt;code>async&lt;/code>方面的工作。&lt;/p>
&lt;h3 id="发散一下异步代码同步热路径和异步机制开销">发散一下：异步代码、同步热路径和异步机制开销&lt;/h3>
&lt;p>&lt;code>async&lt;/code> / &lt;code>await&lt;/code> 中引入的机制非常棒，但是它仍然会是一个会产生惊人栈开销的工作——你可以从 &lt;a href="https://sharplab.io/#v2:D4AQDABCCMCsDcBYAUCkBmKAmCB5ArgE4DCA9gCYCmKA3ihAxAA6ECWAbgIYAulU0ANigAOCADVOAG3yUQAgDwAjUqUkA+CADFpAZwAWAQR0BPAHYBjABQAFVk0oB1Nr0IQA7s8qEAlPUZ1kRiCIAHoQiE4mJkljCEVOcwBrAFoWSh0dIj5KbnM/YIguVwAzXT0IAF4oAE53T0IAOm18fSMzK28kQILQ8N5JSQhuPT5zKUlWUwBzCHMKPjcR4a8I01iAW1JCPnX0nU4p9PzgsIh9UnxJcjiF515TY6CQAHYIAEJLUpa9BoBJHWInAslEklGuwGAEC++j+ANI62iOTBnWOAF8UOjUFjTjomCpimCoVshiMIJQAB6cBGglCTFymKTYCC2exOVguWjHDDiKQyOTyZr6ABK6Uu3A0gsMJgslm8lQ0VGKnDFXUxOm4hHw5m4WjKIsykm4nO6DG5ylUEH+gOBoOuFQVlCVKq5mHNgyt8MRvDtDqdhtVQA=">sharplab.io&lt;/a> 中看到——看看&lt;code>OurCode.FlushAsync&lt;/code> 中生成的机制——和整个 &lt;code>struct &amp;lt;FlushAsync&amp;gt;d__0&lt;/code>。现在，这些代码并&lt;em>不是很糟糕&lt;/em>——它非常努力地尝试在同步路径上避免内存分配——但是&lt;em>没有必要&lt;/em>。&lt;/p>
&lt;p>这里有两种方法可以显著地改善它；一个是压根不去 &lt;code>await&lt;/code> ，通常如果 &lt;code>await&lt;/code> 是在方法中地最后一行并且&lt;strong>我们不需要去处理结果&lt;/strong>：不去 &lt;code>await&lt;/code> ——只要去除&lt;code>async&lt;/code>然后&lt;code>return&lt;/code>这个task——完成或者未完成。在这里我们没办法这样做，因为我们需要去检查返回的状态，但是我们可以通过检查这个task是否&lt;em>已经完成&lt;/em>来对成功的结果进行优化（通过 &lt;code>.IsCompletedSuccessfully&lt;/code> ——如果它已经结束但是有错误，我们仍然需要使用&lt;code>await&lt;/code>来让异常可以正确表现出来）。如果它&lt;em>是&lt;/em>成功完成的，我们可以请求到&lt;code>.Result&lt;/code>。所以我们&lt;em>也&lt;/em>可以将&lt;code>FlushAsync&lt;/code> 写成这样：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> ValueTask&amp;lt;&lt;span style="color:#66d9ef">bool&lt;/span>&amp;gt; Flush(PipeWriter writer)
{
&lt;span style="color:#66d9ef">bool&lt;/span> GetResult(FlushResult flush)
&lt;span style="color:#75715e">// tell the calling code whether any more messages
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// should be written
&lt;/span>&lt;span style="color:#75715e">&lt;/span> =&amp;gt; !(flush.IsCanceled || flush.IsCompleted);
&lt;span style="color:#66d9ef">async&lt;/span> ValueTask&amp;lt;&lt;span style="color:#66d9ef">bool&lt;/span>&amp;gt; Awaited(ValueTask&amp;lt;FlushResult&amp;gt; incomplete)
=&amp;gt; GetResult(&lt;span style="color:#66d9ef">await&lt;/span> incomplete);
&lt;span style="color:#75715e">// apply back-pressure etc
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> flushTask = writer.FlushAsync();
&lt;span style="color:#66d9ef">return&lt;/span> flushTask.IsCompletedSuccessfully
? &lt;span style="color:#66d9ef">new&lt;/span> ValueTask&amp;lt;&lt;span style="color:#66d9ef">bool&lt;/span>&amp;gt;(GetResult(flushTask.Result))
: Awaited(flushTask);
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这在大多数情况（同步完成）下&lt;em>完全避免&lt;/em>了&lt;code>async&lt;/code>/&lt;code>await&lt;/code> 机制——如我们再次在 &lt;a href="https://sharplab.io/#v2:D4AQDABCCMCsDcBYAUCkBmKAmCB5ArgE4DCA9gCYCmKA3ihAxAA6ECWAbgIYAulU0ANggA1TgBt8lEAIA8AI1KkxAPggAxCQGcAFgAoACqyaUA6m16EIAd3OVCASnqM6yRm4gKlEAOKVuAJUpNfDFuXQ18HUDg0IgAMy1tR1d3VIB6NIheMTEs7T4AY3ExVgA7AHMIAoo+K3zufMtOUoBPCABbUkI+dqDNTnKgp1S3DIgdUhDyD1rzXlLhkYYAXlUAQl0EyO0AOgBJTWJmgsoxSmngYHjE/cPSdqYz3nJ7JFQU1JAADhFxSWl5IoVBAAIJWTisZ66UQSKSyCJRIIhbiqMrVB5PSjJJZuVY+PzRZG6EAATggaPujz8WLei1GmU4TEebTknAKAGsALQsPpEPh+Ap0xhcSxbHTSCDLay2Qg7BHaEGaFqlAq6V4oIUMEAAdmu22ktzIGOp5AAyvgCidNJo4iExC1Ne4APwQUqUKy/WEAzwqXS+AJI0KbRIGwmhezYnEMABcoPBkPOwf1AnVHwgAF8UJn3igxpomIo4ud4l08vyAB6cY0oMoWUribAQQzGMwJwi0RYYT3/eGJMMo9SJRXK1X2SWqKhxTjIt7ZzTcQgW7iD7b9jtprs+iAHI4q07FvGT6ehN5uTdA7d3Y3PccQI8zrNAA=">sharplab.io&lt;/a>中看到的一样。我要强调：如果代码是经常（或仅仅）进行&lt;em>真正的异步行为&lt;/em>时，这样做是完全没有必要的；它&lt;em>只&lt;/em>对于那些结果通常（或仅仅）会同步地产生时才有帮助。&lt;/p>
&lt;p>(译注：对于&lt;code>ValueTask&lt;/code>的&amp;quot;hot path&amp;quot;场景的使用，这里有个视频讲过一些，以及其它一些.NET中新的优化性能的方法： &lt;a href="https://www.youtube.com/watch?v=dVKUYP_YALg">Adam Sitnik - State of the .NET Performance&lt;/a>)&lt;/p>
&lt;h3 id="那么reader呢">那么Reader呢？&lt;/h3>
&lt;p>就像我们多次看到的一样，reader总是稍微复杂一些——我们无从得知一个单独的“读”操作是否会准确包含一个入站消息，我们也许需要开启循环直到我们获取到了所有所需的数据，并且我们也许需要推回一些&lt;em>额外的&lt;/em>数据。因此，让我们假设我们想要消费某种单一的消息：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="color:#66d9ef">async&lt;/span> ValueTask&amp;lt;SomeMessageType&amp;gt; GetNextMessage(
PipeReader reader,
CancellationToken cancellationToken = &lt;span style="color:#66d9ef">default&lt;/span>)
{
&lt;span style="color:#66d9ef">while&lt;/span> (&lt;span style="color:#66d9ef">true&lt;/span>)
{
&lt;span style="color:#66d9ef">var&lt;/span> read = &lt;span style="color:#66d9ef">await&lt;/span> reader.ReadAsync(cancellationToken);
&lt;span style="color:#66d9ef">if&lt;/span> (read.IsCanceled) ThrowCanceled();
&lt;span style="color:#75715e">// can we find a complete frame?
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> buffer = read.Buffer;
&lt;span style="color:#66d9ef">if&lt;/span> (TryParseFrame(
buffer,
&lt;span style="color:#66d9ef">out&lt;/span> SomeMessageType nextMessage,
&lt;span style="color:#66d9ef">out&lt;/span> SequencePosition consumedTo))
{
reader.AdvanceTo(consumedTo);
&lt;span style="color:#66d9ef">return&lt;/span> nextMessage;
}
reader.AdvanceTo(buffer.Start, buffer.End);
&lt;span style="color:#66d9ef">if&lt;/span> (read.IsCompleted) ThrowEOF();
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这里我们从pipe中获取了&lt;em>一些&lt;/em>数据，进行退出检查（比如取消）。然后我们&lt;em>尝试寻找一个消息&lt;/em>，这是什么意思取决于你具体的代码——它可以是：&lt;/p>
&lt;ul>
&lt;li>从缓冲区中寻找某些特定的值，比如一个ASCII行尾，然后把所有到这里的数据当作一个消息（丢弃行尾）&lt;/li>
&lt;li>解析一个定义良好的二进制帧头，获取其内容长度，通过检查获取这样长度的数据然后处理&lt;/li>
&lt;li>或者其它你需要的！&lt;/li>
&lt;/ul>
&lt;p>如果我们&lt;em>能够&lt;/em>获取到一个消息，我们可以告诉pipe令其丢弃我们已经消费过的数据——通过 &lt;code>AdvanceTo(consumedTo)&lt;/code>，在这里使用我们自己的帧解析代码告诉我们消费了多少。如果我们&lt;em>没能&lt;/em>获取一个消息，我们要做的第一件事就是告诉pipe我们什么也没消费，尽管我们尝试读取了所有数据——通过 &lt;code>reader.AdvanceTo(buffer.Start, buffer.End)&lt;/code>。在这里，会有两种可能：&lt;/p>
&lt;ul>
&lt;li>我们还没有获得足够的数据&lt;/li>
&lt;li>pipe已经死亡，我们&lt;em>再也不会&lt;/em>获得足够的数据&lt;/li>
&lt;/ul>
&lt;p>我们在通过 &lt;code>read.IsCompleted&lt;/code> 检查了这些，在第二种情况时报告错误；否则我们继续循环，等待更多数据。那么剩下的，就是我们的帧解析——我们已经把复杂的IO管理降低成了简单的操作；比如，如果我们的消息是以行标记分隔：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="color:#66d9ef">private&lt;/span> &lt;span style="color:#66d9ef">static&lt;/span> &lt;span style="color:#66d9ef">bool&lt;/span> TryParseFrame(
ReadOnlySequence&amp;lt;&lt;span style="color:#66d9ef">byte&lt;/span>&amp;gt; buffer,
&lt;span style="color:#66d9ef">out&lt;/span> SomeMessageType nextMessage,
&lt;span style="color:#66d9ef">out&lt;/span> SequencePosition consumedTo)
{
&lt;span style="color:#75715e">// find the end-of-line marker
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> eol = buffer.PositionOf((&lt;span style="color:#66d9ef">byte&lt;/span>)&lt;span style="color:#e6db74">&amp;#39;\n&amp;#39;&lt;/span>);
&lt;span style="color:#66d9ef">if&lt;/span> (eol == &lt;span style="color:#66d9ef">null&lt;/span>)
{
nextMessage = &lt;span style="color:#66d9ef">default&lt;/span>;
consumedTo = &lt;span style="color:#66d9ef">default&lt;/span>;
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">false&lt;/span>;
}
&lt;span style="color:#75715e">// read past the line-ending
&lt;/span>&lt;span style="color:#75715e">&lt;/span> consumedTo = buffer.GetPosition(&lt;span style="color:#ae81ff">1&lt;/span>, eol.Value);
&lt;span style="color:#75715e">// consume the data
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">var&lt;/span> payload = buffer.Slice(&lt;span style="color:#ae81ff">0&lt;/span>, eol.Value);
nextMessage = ReadSomeMessageType(payload);
&lt;span style="color:#66d9ef">return&lt;/span> &lt;span style="color:#66d9ef">true&lt;/span>;
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这里&lt;code>PositionOf&lt;/code> 尝试获取第一个行标记的位置。如果一个也找不到，我们就放弃，否则我们将&lt;code>consumedTo&lt;/code> 设为”行标记+1“（即我们会消费行标记），然后我们分割我们的缓冲区来创建一个子集，表示&lt;em>不包括&lt;/em>行标记的内容，这样我们就可以解析了。最终，我们报告成功，并且庆祝我们可以简单地解析Linux风格的行尾。&lt;/p>
&lt;h3 id="这里的重点是什么">这里的重点是什么？&lt;/h3>
&lt;p>用这些&lt;em>和大多数最简单最简朴的&lt;code>Stream&lt;/code>版本（没有任何nice的特性）非常相似&lt;/em>的最少量的代码，我们的应用现在有了一个reader和writer，利用广泛的能力确保高效和有效的处理。你可以用&lt;code>Stream&lt;/code>&lt;em>来做所有的这些事&lt;/em>，但是这样&lt;em>真的、真的很难&lt;/em>去做好做可靠。通过将所有的这些特性集成进框架，许多代码都可以受益于这一单独的实现。并且它也给了那些直接在pipeline API上开发并且对自定义pipeline端点和修饰感兴趣的人更多的未来空间。&lt;/p>
&lt;h3 id="总结">总结&lt;/h3>
&lt;p>在这节，我们研究了pipeline使用的内存模型和其如何帮助我们避免分配内存，然后我们研究了怎样才可以将pipeline与现有的API和系统（如&lt;code>Stream&lt;/code>）进行交互——并且我们介绍了 &lt;code>Pipelines.Sockets.Unofficial&lt;/code> 这样的可用的工具库。我们研究了在不支持 span/memory 代码的API上集成它们的可用选项，最终我们展示了和pipeline交互的&lt;em>真正的调用代码&lt;/em>是什么样子的（并且简单地介绍了如何优化那些通常是同步的&lt;code>async&lt;/code>代码）——展示了我们的&lt;em>应用代码&lt;/em>会是什么样子。在最后一部分，我们将会研究如何在开发现实中的库，比如&lt;code>StackExchange.Redis时&lt;/code>，将我们学到的这些知识点联系起来——讨论我们在代码里需要解决哪些复杂点，而pipeline又如何将它们变得简单。&lt;/p></description></item><item><title>Pipelines - .NET中的新IO API指引(一)</title><link>http://suraciii.github.io/posts/trans-pipelines-marcgravell-1/</link><pubDate>Sun, 01 Jul 2018 00:00:00 +0000</pubDate><guid>http://suraciii.github.io/posts/trans-pipelines-marcgravell-1/</guid><description>&lt;p>原文：&lt;a href="https://blog.marcgravell.com/2018/07/pipe-dreams-part-1.html">Pipelines - a guided tour of the new IO API in .NET, part 1&lt;/a>&lt;/p>
&lt;p>作者：marcgravell&lt;/p>
&lt;p>大约两年前，我发表了一篇&lt;a href="https://blog.marcgravell.com/2016/09/channelling-my-inner-geek.html">关于.NET中即将到来的体验性新IO API&lt;/a>的博文——在那时它被叫做&amp;quot;Channels&amp;quot;；在2018年的五月末，它终于在&lt;a href="https://www.nuget.org/packages/System.IO.Pipelines/">System.IO.Pipelines&lt;/a>命名空间中落地，我对这系列API巨感兴趣，而在几个星期前，我被分配去用&amp;quot;Pipelines&amp;quot;改造&lt;code>StackExchange.Redis&lt;/code>以&lt;a href="https://github.com/StackExchange/StackExchange.Redis/issues/871">作为我们2.0更新的一部分&lt;/a>&lt;/p>
&lt;p>我希望在这个系列可以讨论：&lt;/p>
&lt;ul>
&lt;li>&amp;ldquo;Pipelines&amp;quot;是什么&lt;/li>
&lt;li>如何在代码方面使用它们&lt;/li>
&lt;li>什么时候你也许会想要使用它们&lt;/li>
&lt;/ul>
&lt;p>为了表达地更具体，在介绍完&amp;quot;Pipelines&amp;quot;后，我打算大篇幅地讲解StackExchange.Redis中的相关转换，并且作为讨论在不同场景下它分别解决了哪些问题的一部分。简略地说：在几乎所有的情况下，答案可以概括为：&lt;/p>
&lt;p>&lt;em>它非常适合那些在IO代码中复杂却普遍的痛点；使我们可以替换掉那些丑陋的封装(kludge)、变通(workaround)或妥协(compromise)——用一个在框架中设计优雅的专门的解决方案。&lt;/em>&lt;/p>
&lt;p>我敢肯定，我下面所覆盖的那些痛点，对于那些工作在&amp;quot;数据协议(data protocol)&amp;ldquo;层面的人来说，一定非常熟悉。&lt;/p>
&lt;h3 id="pipelines替代完善了什么">Pipelines替代/完善了什么？&lt;/h3>
&lt;p>首先：现有框架中最接近Pipelines的是什么？很简单，Stream ,Stream API对于那些做过序列化或是数据协议工作的人来说非常熟悉，但是，Stream其实是一个非常模糊的API——它在不同的场景表现地非常不同：&lt;/p>
&lt;ul>
&lt;li>一些Stream是只读的，一些是只写的，一些是读/写的&lt;/li>
&lt;li>一样的实体类型有时候是只读的，而有时是只写的（比如&lt;code>DeflateStream&lt;/code>)&lt;/li>
&lt;li>当一个Stream是读/写时，它像是一个磁带，读写操作全作用于同样的下层数据（&lt;code>FileStream&lt;/code>,&lt;code>MemoryStream&lt;/code>) ，而有时它像是两个不同的Stream，读写作用于本质上完全不同的两个Stream(&lt;code>NetworkStream&lt;/code>, &lt;code>SslStream&lt;/code>)——即duplex stream&lt;/li>
&lt;li>在许多deplex(双工)场景下，很难甚至根本不可能表达“之后没有新数据会到来，但是你应该继续读取数据直到结束“——只有&lt;code>Close()&lt;/code>，而它会将deplex的两部分同时关闭&lt;/li>
&lt;li>有时Stream会是可探查的(Seekable)并且支持&lt;code>Position&lt;/code>和&lt;code>Length&lt;/code>的概念，不过大多数不会&lt;/li>
&lt;li>由于API随着时间的推移，通常会有多种方法来表达同一种操作——比如，我们可以用Read(同步)，BeginRead/EndRead(IAsyncResult模式的异步)，或者ReadAsync(async/await模式的异步)；在多数情况下，调用代码无从得知到底哪种方法才是推荐的/最佳的API&lt;/li>
&lt;li>如果你使用任何一种异步API，通常很难清楚分辨它的线程模型是什么；它实质上是同步的吗？如果不是，是哪个线程会回调？它用了同步上下文吗？线程池？IO complection-port线程？&lt;/li>
&lt;li>并且在最近，有了允许使用&lt;code>Span&amp;lt;byte&amp;gt;&lt;/code>/&lt;code>Memory&amp;lt;byte&amp;gt;&lt;/code>替换&lt;code>byte[]&lt;/code>的API——再一次的，调用者无法知道哪一种才是”更好的“API&lt;/li>
&lt;li>这种API本质上&lt;em>鼓励&lt;/em>复制数据；需要缓冲区？那是将数据复制到了另一块内存中，需要一个尚未处理的数据仓库？同样是复制了数据到另一块内存中&lt;/li>
&lt;/ul>
&lt;p>所以即使在我们开始讨论现实世界中的Stream例子和使用它们所导致的问题之前，很明显Stream API本身已经有了&lt;em>很多&lt;/em>问题，所以首先显而易见的是，Pipelines解决了这些混乱&lt;/p>
&lt;h3 id="什么是pipelines">什么是Pipelines&lt;/h3>
&lt;p>说起&amp;quot;Pipelines&amp;rdquo;，我指的是一组4个关键API，它们实现对一个二进制流解耦、重叠(overlapped)的读写访问，包括缓冲区管理(池化，回收)，线程感知，丰富的积压控制，和通过背压达到的溢出保护——所有这些都基于一个围绕非连续内存设计的 API，That&amp;rsquo;s a &lt;em>heck&lt;/em> of a word salad——但是不要担心，我会讨论每一个元素来解释我的意思。&lt;/p>
&lt;h3 id="从简单的开始对一个单独的管道进行写入和读取">从简单的开始：对一个单独的管道进行写入和读取&lt;/h3>
&lt;p>让我们先准备一个对等的Stream，然后写入一些简单的东西，然后再读取回来——坚持只使用Stream API。我们将只使用ASCII文本以便不用担心有任何复杂编码的状况，并且我们的读写代码不对下层数据流做任何假设。我们只是写入数据，并且读取到流的末尾从而消费它。&lt;/p>
&lt;p>我们将先用Stream来做这些——熟悉的领域，然后我们用Pipelines重新实现它，来看其中的相似和不同之处，在之后，我们将研究在其内部究竟发生了什么，然后我们就能明白为什么它会吸引我们&lt;/p>
&lt;p>也许你会说&amp;quot;啊，我想起来了&lt;code>TextReader&lt;/code>/&lt;code>TextWriter&lt;/code>&amp;quot;，我故意不去使用它们——因为我在这里是在尝试谈论Stream API，这样我们的例子可以扩展到广泛的数据协议和场景&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="color:#66d9ef">using&lt;/span> (MemoryStream ms = &lt;span style="color:#66d9ef">new&lt;/span> MemoryStream())
{
&lt;span style="color:#75715e">// write something
&lt;/span>&lt;span style="color:#75715e">&lt;/span> WriteSomeData(ms);
&lt;span style="color:#75715e">// rewind - MemoryStream works like a tape
&lt;/span>&lt;span style="color:#75715e">&lt;/span> ms.Position = &lt;span style="color:#ae81ff">0&lt;/span>;
&lt;span style="color:#75715e">// consume it
&lt;/span>&lt;span style="color:#75715e">&lt;/span> ReadSomeData(ms);
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>现在，要写入Stream，调用方需要获取并填充一个缓冲区然后将其传递给Stream，此时我们为了简化它，使用同步的API，并且简单地分配一个byte数组&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="color:#66d9ef">void&lt;/span> WriteSomeData(Stream stream)
{
&lt;span style="color:#66d9ef">byte&lt;/span>[] bytes = Encoding.ASCII.GetBytes(&lt;span style="color:#e6db74">&amp;#34;hello, world!&amp;#34;&lt;/span>);
stream.Write(bytes, &lt;span style="color:#ae81ff">0&lt;/span>, bytes.Length);
stream.Flush();
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>注意：如果要提高效率地话，在上面的代码中有很多可以做的，但是这不是重点。所以如果你熟悉这类代码并且看着膈应，别慌，之后我们会让它变得更丑陋——呃，我是说更有效率&lt;/p>
&lt;p>读逻辑的代码会比写逻辑更复杂，因为读代码无法假定一次单独的调用就可以获得所有的数据，一个对Stream的读操作可能会什么也不返回(表明已经读到数据末尾)，也可能填满我们的缓冲区，或者只是返回了一个字节即使我们准备了一个巨大的缓冲区。所以Stream的读代码大多数会是一个循环：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="color:#66d9ef">void&lt;/span> ReadSomeData(Stream stream)
{
&lt;span style="color:#66d9ef">int&lt;/span> bytesRead;
&lt;span style="color:#75715e">// note that the caller usually can&amp;#39;t know much about
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// the size; .Length is not usually usable
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">byte&lt;/span>[] buffer = &lt;span style="color:#66d9ef">new&lt;/span> &lt;span style="color:#66d9ef">byte&lt;/span>[&lt;span style="color:#ae81ff">256&lt;/span>];
&lt;span style="color:#66d9ef">do&lt;/span>
{
bytesRead = stream.Read(buffer, &lt;span style="color:#ae81ff">0&lt;/span>, buffer.Length);
&lt;span style="color:#66d9ef">if&lt;/span> (bytesRead &amp;gt; &lt;span style="color:#ae81ff">0&lt;/span>)
{ &lt;span style="color:#75715e">// note this only works for single-byte encodings
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">string&lt;/span> s = Encoding.ASCII.GetString(
buffer, &lt;span style="color:#ae81ff">0&lt;/span>, bytesRead);
Console.Write(s);
}
} &lt;span style="color:#66d9ef">while&lt;/span> (bytesRead &amp;gt; &lt;span style="color:#ae81ff">0&lt;/span>);
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>现在我们将它翻译成pipelines，一个Pipe可以大略地比作一个&lt;code>MemoryStream&lt;/code>，除了不能多次倒带(rewind)，数据是一个简单的先进先出队列，我们有一个&lt;code>writer&lt;/code>API可以在一端推入数据，而一个&lt;code>reader&lt;/code>API可以在另一端将数据取出，Pipe就是坐在二这之中的一个缓冲区。让我们重现之前的场景，但是用一个Pipe替换掉&lt;code>MemoryStream&lt;/code>（同样，实践中我们通常不会这么做，但是易于举例）：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">Pipe pipe = &lt;span style="color:#66d9ef">new&lt;/span> Pipe();
&lt;span style="color:#75715e">// write something
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">await&lt;/span> WriteSomeDataAsync(pipe.Writer);
&lt;span style="color:#75715e">// signal that there won&amp;#39;t be anything else written
&lt;/span>&lt;span style="color:#75715e">&lt;/span>pipe.Writer.Complete();
&lt;span style="color:#75715e">// consume it
&lt;/span>&lt;span style="color:#75715e">&lt;/span>&lt;span style="color:#66d9ef">await&lt;/span> ReadSomeDataAsync(pipe.Reader);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>首先我们用默认选项创造一个pipe，然后我们写入它。注意在Pipe中的IO操作通常都是异步的，所以我们需要await我们的两个帮助方法，同样注意，我们并没有将这个Pipe传入它们——和Stream不同，pipelines 对于读和写有着不同的API层面，所以我们将一个&lt;code>PipeWriter&lt;/code> 传入帮助方法用来写入数据，然后传入一个&lt;code>PipeReader&lt;/code>来读取数据，写入数据后，我们在&lt;code>PipeWriter&lt;/code>上调用&lt;code>Complete()&lt;/code>。我们不需要在&lt;code>MemoryStream&lt;/code>中做这个因为当它到达缓冲数据的末尾时会自动&lt;a href="https://en.wikipedia.org/wiki/End-of-file">EOFs&lt;/a>——但是在一些其它的Stream实现中——尤其是单向流——我们也许需要在写入数据后调用&lt;code>Close&lt;/code>&lt;/p>
&lt;p>好了，那么我们的&lt;code>WriteSomeDataAsync&lt;/code> 是什么呢？注意，我在下面的代码中故意多写了注释：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="color:#66d9ef">async&lt;/span> ValueTask WriteSomeDataAsync(PipeWriter writer)
{
&lt;span style="color:#75715e">// use an oversized size guess
&lt;/span>&lt;span style="color:#75715e">&lt;/span> Memory&amp;lt;&lt;span style="color:#66d9ef">byte&lt;/span>&amp;gt; workspace = writer.GetMemory(&lt;span style="color:#ae81ff">20&lt;/span>);
&lt;span style="color:#75715e">// write the data to the workspace
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">int&lt;/span> bytes = Encoding.ASCII.GetBytes(
&lt;span style="color:#e6db74">&amp;#34;hello, world!&amp;#34;&lt;/span>, workspace.Span);
&lt;span style="color:#75715e">// tell the pipe how much of the workspace
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// we actually want to commit
&lt;/span>&lt;span style="color:#75715e">&lt;/span> writer.Advance(bytes);
&lt;span style="color:#75715e">// this is **not** the same as Stream.Flush!
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">await&lt;/span> writer.FlushAsync();
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>首先要注意的是，在处理pipelines时：不是你控制缓冲区，而是Pipe，回想我们的Stream代码，读和写代码都创建了本地byte[]，但是在这里我们没有，相反，我们通过&lt;code>GetMemory&lt;/code> (或者它的孪生方法&lt;code>GetSpan&lt;/code>)向Pipe请求了一个缓冲区(&lt;code>workspace&lt;/code>)，就先你从名字中想到的那样，这给了我们一个&lt;code>Memory&amp;lt;byte&amp;gt;&lt;/code>或是一个&lt;code>Span&amp;lt;byte&amp;gt;&lt;/code> ——其容量为最少20字节&lt;/p>
&lt;p>获取这个缓冲区后，将我们的字符串编码进去，这意味着我们是直接写入Pipe的内存，并且记录下&lt;em>实际上&lt;/em>我们使用了多少字节，然后我们通过&lt;code>Advance&lt;/code>告诉Pipe，我们不受之前请求的20字节的限制——我们可以写入0，20，甚至50字节，最后一个看起来也许会令人意外，但是这实际上是被鼓励的！之前的重点是“至少”——writer可以时间上给我们一个比我们请求的大的很多的缓冲区。当处理较大的数据时，得陇望蜀是很常见的：请求一个我们能有效利用的最小空间，但是之后在检查提供给我们的memory/span的体积后，再决定最终实际写入多少。&lt;/p>
&lt;p>对&lt;code>Advance&lt;/code>的调用很重要，它意味着一次写操作的终结，使得Pipe中的数据可用从而被reader消费。对&lt;code>FlushAsync&lt;/code> 的调用同样重要，但是有微妙的区别，但是在我们可以充分地阐明这区别是什么前，我们需要先看一看reader。这是我们的&lt;code>ReadSomeDataAsync&lt;/code> 方法：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">&lt;span style="color:#66d9ef">async&lt;/span> ValueTask ReadSomeDataAsync(PipeReader reader)
{
&lt;span style="color:#66d9ef">while&lt;/span> (&lt;span style="color:#66d9ef">true&lt;/span>)
{
&lt;span style="color:#75715e">// await some data being available
&lt;/span>&lt;span style="color:#75715e">&lt;/span> ReadResult read = &lt;span style="color:#66d9ef">await&lt;/span> reader.ReadAsync();
ReadOnlySequence&amp;lt;&lt;span style="color:#66d9ef">byte&lt;/span>&amp;gt; buffer = read.Buffer;
&lt;span style="color:#75715e">// check whether we&amp;#39;ve reached the end
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#75715e">// and processed everything
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">if&lt;/span> (buffer.IsEmpty &amp;amp;&amp;amp; read.IsCompleted)
&lt;span style="color:#66d9ef">break&lt;/span>; &lt;span style="color:#75715e">// exit loop
&lt;/span>&lt;span style="color:#75715e">&lt;/span>
&lt;span style="color:#75715e">// process what we received
&lt;/span>&lt;span style="color:#75715e">&lt;/span> &lt;span style="color:#66d9ef">foreach&lt;/span> (Memory&amp;lt;&lt;span style="color:#66d9ef">byte&lt;/span>&amp;gt; segment &lt;span style="color:#66d9ef">in&lt;/span> buffer)
{
&lt;span style="color:#66d9ef">string&lt;/span> s = Encoding.ASCII.GetString(
segment.Span);
Console.Write(s);
}
&lt;span style="color:#75715e">// tell the pipe that we used everything
&lt;/span>&lt;span style="color:#75715e">&lt;/span> reader.AdvanceTo(buffer.End);
}
}
&lt;/code>&lt;/pre>&lt;/div>&lt;p>就像Stream例子一样，我们有一个循环持续到我们读取到数据的末尾，在Stream中，这种情况通过&lt;code>Read&lt;/code>方法返回一个非正结果时判定，但是在pipeline中有两种检查方式：&lt;/p>
&lt;ul>
&lt;li>&lt;code>read.IsCompleted&lt;/code>告诉我们那个写pipe是否被通知完成，并且不会再有数据被写入(pipe.Writer.Complete();之前代码中的这句)&lt;/li>
&lt;li>&lt;code>buffer.IsEmpty&lt;/code>告诉我们&lt;em>在这次操作&lt;/em>中没有剩余的数据需要处理&lt;/li>
&lt;/ul>
&lt;p>如果pipe中不再有数据并且writer被通知complete，那么将永远不会有东西存在于这个pipe中，那我们就可以退出了&lt;/p>
&lt;p>如果我们有数据存在，我们可以查看缓冲区，所以首先——我们要谈谈缓冲；在代码中那是个新类型&lt;code>ReadOnlySequence&amp;lt;byte&amp;gt;&lt;/code>——这个概念结合了几个角色：&lt;/p>
&lt;ul>
&lt;li>描述不连续内存，特别是一个由0个，1个或多个&lt;code>ReadOnlyMemory&amp;lt;byte&amp;gt;&lt;/code>块组成的序列&lt;/li>
&lt;li>描述在这个数据流中的一个逻辑位置(&lt;code>SequencePosition&lt;/code>)—— in particular via &lt;code>buffer.Start&lt;/code> and &lt;code>buffer.End&lt;/code>&lt;/li>
&lt;/ul>
&lt;p>&lt;code>非连续&lt;/code>在此非常重要，我们很快将看到这些数据实际上的去向，但在读方面：我们需要准备好处理可以跨多个部分传播的数据。在这里，我们通过简单的遍历缓冲区，轮流解码每一段数据来达到目的。请注意, 即使 API 被设计为可以描述多个非连续缓冲区, 但通常情况下, 接收到的数据在单个缓冲区中是连续的。在这种情况下, 通常可以为单个缓冲区编写优化的实现。你可以通过检查&lt;code>buffer.IsSingleSegment&lt;/code>和访问&lt;code>buffer.First&lt;/code>来做到。&lt;/p>
&lt;p>最终，我们调用&lt;code>AdvanceTo&lt;/code>，告诉Pipe我们实际上使用了多少数据。&lt;/p>
&lt;h3 id="关键点你无需取出你提供的所有数据">关键点：你无需取出你提供的所有数据&lt;/h3>
&lt;p>对比流：当你在Stream上调用Read时，它会将所有数据放到你给它的缓冲区中，在大多数现实场景中，并不是总是能及时消费掉所有的数据——maybe it only makes sense to consider &amp;ldquo;commands&amp;rdquo; as &amp;ldquo;entire text lines&amp;rdquo;,, and you haven&amp;rsquo;t yet seen a &lt;code>cr&lt;/code>/&lt;code>lf&lt;/code> in the data. 对于Stream来说，这点很坑——一旦数据给了你，就是你的问题了，如果你现在用不上它，那你就要在某处储备这段数据，但是对于Pipelines，你可以告诉它你消费过了。在我们的例子中，我们通过传递&lt;code>buffer.End&lt;/code>到&lt;code>AdvanceTo&lt;/code>来告诉它我们消费掉了之前提供的所有数据。这意味着我们将永远不会再见到这段数据，就像用Stream一样，但是，我们也可以传递&lt;code>buffer.Start&lt;/code>，意味着“我们什么都还没使用”——及时我们能够检查这段数据，它也依然会留存在pipe中以供后续读取。我们也可以获取缓冲区中任意的&lt;code>SequencePosition&lt;/code> 值——例如如果我们读取20字节——所以我们可以完全控制有多少数据被从pipe中丢弃。这里有两种方法取得&lt;code>SequencePosition&lt;/code> ：&lt;/p>
&lt;ul>
&lt;li>你可以就像&lt;code>Slice(...)&lt;/code>一个 &lt;code>Span&amp;lt;T&amp;gt;&lt;/code> o或者&lt;code>Memory&amp;lt;T&amp;gt;&lt;/code>一样&lt;code>Slice(...)&lt;/code>一个&lt;code>ReadOnlySequence&amp;lt;byte&amp;gt;&lt;/code> ——然后访问子集中的&lt;code>.Start&lt;/code>或&lt;code>.End&lt;/code>&lt;/li>
&lt;li>你可以使用&lt;code>ReadOnlySequence&amp;lt;byte&amp;gt;&lt;/code>中的&lt;code>.GetPosition(...)&lt;/code> 方法，它返回一个相关位置而&lt;em>无需&lt;/em>真正分割&lt;/li>
&lt;/ul>
&lt;p>更微妙的是：我们可以分别告诉它我们消费了一些数量，但是我们已检查了另一个不同的数量，这里最常见的例子是表达“你可以丢弃这么多——这些我做完了；但是我看完了所有的数据，我此时无法处理——我需要更多数据（you can drop &lt;em>this much&lt;/em> - I&amp;rsquo;m done with that; but I looked at everything, I can&amp;rsquo;t make any more progress at the moment - I need more data）”，具体来说：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4">&lt;code class="language-csharp" data-lang="csharp">reader.AdvanceTo(consumedToPosition, buffer.End);
&lt;/code>&lt;/pre>&lt;/div>&lt;p>这里正是&lt;code>PipeWriter.FlushAsync()&lt;/code>和&lt;code>PipeReader.ReadAsync()&lt;/code>微妙的相互作用出场的地方了，我之前跳过了&lt;code>PipeWriter.FlushAsync()&lt;/code>，它实际上在一次调用里提供了两个功能：&lt;/p>
&lt;ul>
&lt;li>如果存在一个&lt;code>ReadAsync&lt;/code> 调用，它会被注意到，因为它需要数据，然后它唤醒reader，使读取循环继续&lt;/li>
&lt;li>如果writer快过reader，比如pipe中充满了没有被reader清楚的数据，它会挂起writer(通过同步的not completing)——当pipe有了更多空间后，才会被重新激活(writer挂起/恢复的阈值可以在创建Pipe实例时被指定)&lt;/li>
&lt;/ul>
&lt;p>显然, 这些概念在我们的示例中没有发挥作用, 但它们是Pipelines工作原理的核心思想。将数据推送回pipe的能力极大地简化了大量 IO 场景。实际上, 我在有pipelines之前看到的每一个协议处理代码都有大量的代码与处理不完整数据的积压有关——它是这样一个重复的逻辑, 我非常高兴地看到它能在框架中被处理得很好。&lt;/p>
&lt;h3 id="唤醒或者说响应式指的是什么">“唤醒”或者说“响应式”指的是什么&lt;/h3>
&lt;p>你可能会注意到，我并没有真正定义我之前表达的意思，在表层上，我的意思是：对于&lt;code>ReadAsync&lt;/code> 或&lt;code>FlushAsync&lt;/code> 的一个await操作在其返回之前是未完成的，然后现在异步延续被产生，允许我们的async方法恢复执行，是，没错，不过这只是重新说明了 &lt;code>async&lt;/code>/&lt;code>await&lt;/code> 是什么意思。但是我debug的重点关注在于代码运行于哪个线程上——原因我会在之后的系列中讨论。所以说 &amp;ldquo;异步延续被产生 &amp;quot; 对我来说还不够。我想了解是谁在调用它, 就线程而言。最常见的答案是：&lt;/p>
&lt;ul>
&lt;li>它通过&lt;code>SynchronizationContext&lt;/code> 委托（注意：在许多系统中&lt;em>没有&lt;/em>&lt;code>SynchronizationContext&lt;/code> ）&lt;/li>
&lt;li>触发状态更改的线程会在状态更改时使用, 以产生延续&lt;/li>
&lt;li>全局线程池会被用来产生延续&lt;/li>
&lt;/ul>
&lt;p>在某些情况下，所有这些都可以是没问题的，而在某些情况下，所有这些都可能是糟糕的！同步上下文是一种完善的机制，可以从工作线程返回到主应用程序线程 (例外：桌面应用程序中的 UI 线程)。然而，它是没有必要的如果只是说我们完成了一个IO操作然后准备跳回一个应用线程；并且这么做会实际上将大量IO代码和数据处理代码转移到应用线程——这通常是我们想要避免的。并且，如果应用代码在异步调用时使用了&lt;code>Wait()&lt;/code>或&lt;code>.Result&lt;/code>会导致死锁（假设你不是故意的）。第二种选项（“内联”地在一个触发它的线程上执行回调）可能会有问题，因为它可以偷取你想要用来做别的事的线程（并且有可能导致死锁）；并且在某些极端情况下，当两个异步方法本质上作为协程运行时，可能会导致stack-dive（最终栈溢出）。最后一个选项 (全局线程池) 没有前两个的问题, 但在某些负载条件下可能会遇到严重问题——我将在本系列后面的部分讨论这一点。&lt;/p>
&lt;p>但是好消息是，pipelines在这里给了你控制权。当创建Pipe实例时，我们可以提供&lt;code>PipeScheduler&lt;/code> 实例给reader和writer（分别地）使用。&lt;code>PipeScheduler&lt;/code> 用来执行这些激活。如果没有制定，那么它默认受i按检查&lt;code>SynchronizationContext&lt;/code>，然后使用全局线程池使用“内联”延续（使用那个导致状态改变的线程）作为另一个可用选项。但是：&lt;em>你可以提供你对于&lt;code>PipeScheduler&lt;/code>自己的实现&lt;/em>，给予你对线程模型的完全控制。&lt;/p>
&lt;h3 id="总结">总结&lt;/h3>
&lt;p>所以：我们已经研究了什么是&lt;code>Pipe&lt;/code> ，和我们怎样才能用&lt;code>PipeWriter&lt;/code>写入一个pipe，和用&lt;code>PipeReader&lt;/code> 从pipe中读取——和怎样&amp;quot;advance&amp;quot;二者。我们已经研究了其于Stream的相似和差异，我们讨论了&lt;code>ReadAsync()&lt;/code>和 &lt;code>FlushAsync()&lt;/code> 怎样交互控制writer和reader的分片执行。我们研究了通过pipe提供所有缓冲区后，对缓冲区的责任怎样被反转——和pipe怎样简化了积压数据的管理。最终，我们讨论了激活对&lt;code>await&lt;/code>操作的延续进行激活的线程模型。&lt;/p>
&lt;p>这对于第一步来说可能已经足够了。在之后，我们将研究pipelines工作时的内存模型——比如数据存活在哪里。我们也将研究&lt;em>如何在现实场景中利用pipelines来开始做些有趣的东西&lt;/em>。&lt;/p></description></item></channel></rss>